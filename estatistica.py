# üî¢ Bibliotecas de an√°lise de dados
import pandas as pd
import numpy as np

# üìä Visualiza√ß√£o de dados
import matplotlib.pyplot as plt
import seaborn as sns

# üì¶ Modelos estat√≠sticos
import statsmodels.api as sm
from statsmodels.stats.stattools import durbin_watson
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.miscmodels.ordinal_model import OrderedModel
from scipy.stats import chi2_contingency


# üß™ Testes estat√≠sticos
from scipy import stats
from scipy.stats import shapiro, anderson, kstest, norm

# üìà M√©tricas de modelos
from sklearn.metrics import roc_curve, auc

# üíæ Manipula√ß√£o de arquivos/imagens
import base64
from io import BytesIO
import os

# üß† Fun√ß√µes locais do projeto
from suporte import interpretar_coluna
from estilo import aplicar_estilo_minitab

# ‚úÖ Todas as an√°lises come√ßam abaixo, dentro das fun√ß√µes (nunca aqui fora)



def salvar_grafico():
    caminho = "grafico.png"
    plt.tight_layout()
    plt.savefig(caminho)
    plt.close()
    with open(caminho, "rb") as f:
        img_base64 = base64.b64encode(f.read()).decode("utf-8")
    os.remove(caminho)
    return img_base64


def analise_capabilidade_normal(df, colunas_usadas):
    nome_coluna_y = colunas_usadas[0]
    nome_coluna_x = colunas_usadas[1]

    dados = df[nome_coluna_y].dropna().astype(float)
    limites = df[nome_coluna_x].dropna().unique()

    if len(limites) != 2:
        raise ValueError("A coluna de limites deve conter exatamente dois valores num√©ricos (LSL e USL).")

    lsl, usl = sorted(limites)

    media = np.mean(dados)
    desvio_padrao = np.std(dados, ddof=1)
    n = len(dados)

    # Cp e Cpk
    cp = (usl - lsl) / (6 * desvio_padrao)
    cpu = (usl - media) / (3 * desvio_padrao)
    cpl = (media - lsl) / (3 * desvio_padrao)
    cpk = min(cpu, cpl)

    # Pp e Ppk
    pp = (usl - lsl) / (6 * np.std(dados, ddof=0))
    ppu = (usl - media) / (3 * np.std(dados, ddof=0))
    ppl = (media - lsl) / (3 * np.std(dados, ddof=0))
    ppk = min(ppu, ppl)

    # N√≠vel sigma estimado
    sigma_nivel = 3 * cpk

    # üìà Gr√°fico de Capabilidade Estilo Minitab
    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(8, 4))

    # Histograma
    counts, bins, patches = ax.hist(dados, bins=15, color="#A6CEE3", edgecolor='black', alpha=0.9, density=True)

    # Curva normal te√≥rica
    xmin, xmax = ax.get_xlim()
    x = np.linspace(xmin, xmax, 500)
    p = norm.pdf(x, media, desvio_padrao)
    ax.plot(x, p, 'darkred', linewidth=2)

    # Linhas LSL, USL, M√©dia
    ax.axvline(lsl, color='maroon', linestyle='--', linewidth=1.5)
    ax.axvline(usl, color='maroon', linestyle='--', linewidth=1.5)
    ax.axvline(media, color='darkgreen', linestyle='-', linewidth=2)
    ax.text(media, max(p) * 1.05, "Alvo", ha='center', va='bottom', fontsize=10, color='darkgreen')

    # T√≠tulos e layout
    ax.set_title('Capabilidade do Processo (Normal)', fontsize=14, weight='bold')
    ax.set_xlabel(nome_coluna_y)
    ax.set_ylabel('Densidade')
    ax.set_xlim(xmin, xmax)
    plt.tight_layout()

    # Exporta como base64
    buffer = BytesIO()
    plt.savefig(buffer, format='png')
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode('utf-8')
    plt.close()

    # Texto explicativo
    texto = f"""üìä **An√°lise de Capabilidade (Distribui√ß√£o Normal)**

- LSL: {lsl:.4f}
- USL: {usl:.4f}
- M√©dia: {media:.4f}
- Desvio Padr√£o: {desvio_padrao:.4f}
- Cp: {cp:.4f}
- Cpk: {cpk:.4f}
- Pp: {pp:.4f}
- Ppk: {ppk:.4f}
- N√≠vel Sigma estimado: {sigma_nivel:.4f}
"""

    return texto, imagem_base64

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import anderson, shapiro, kstest, norm
from sklearn.preprocessing import PowerTransformer
from io import BytesIO
import base64

from estilo import aplicar_estilo_minitab

def analise_capabilidade_nao_normal(df, colunas_usadas):
    nome_coluna_y = colunas_usadas[0]
    nome_coluna_x = colunas_usadas[1]

    dados = df[nome_coluna_y].dropna().astype(float)
    limites = df[nome_coluna_x].dropna().unique()

    if len(limites) != 2:
        raise ValueError("A coluna de limites deve conter exatamente dois valores num√©ricos (LSL e USL).")

    lsl, usl = sorted(limites)
    media = np.mean(dados)
    desvio_padrao = np.std(dados, ddof=1)
    n = len(dados)

    # Testes de normalidade (agora: basta 1 teste indicar normalidade)
    ad_stat, ad_crit, _ = anderson(dados)
    shapiro_stat, shapiro_p = shapiro(dados)
    ks_stat, ks_p = kstest(dados, 'norm', args=(media, desvio_padrao))

    normal = (ad_stat < ad_crit[2]) or (shapiro_p > 0.05) or (ks_p > 0.05)

    texto = f"""üìä **An√°lise de Capabilidade ‚Äì Dados N√£o Normais**

üîé **Testes de Normalidade:**
- Anderson-Darling: estat√≠stica = {ad_stat:.4f} | 5% crit√©rio = {ad_crit[2]:.4f}
- Shapiro-Wilk: p = {shapiro_p:.4f}
- Kolmogorov-Smirnov: p = {ks_p:.4f}

üß† Resultado: Dados {"normais ‚úÖ" if normal else "n√£o normais ‚ùå"}

"""

    if normal:
        texto += "‚ö†Ô∏è Os dados s√£o normais. Use a ferramenta **Capabilidade Normal**.\n"
        return texto, None

    # Estabilidade (3 sigma + outliers)
    ucl = media + 3 * desvio_padrao
    lcl = media - 3 * desvio_padrao
    instavel = ((dados > ucl) | (dados < lcl)).any()

    q1, q3 = np.percentile(dados, [25, 75])
    iqr = q3 - q1
    limite_inf = q1 - 1.5 * iqr
    limite_sup = q3 + 1.5 * iqr
    outliers = dados[(dados < limite_inf) | (dados > limite_sup)]

    if len(outliers) > 0:
        instavel = True

    texto += f"\nüìà **Estabilidade do Processo:** {'‚ö†Ô∏è Inst√°vel' if instavel else '‚úÖ Est√°vel'}\n"
    texto += f"üö® **Outliers (IQR):** {len(outliers)} valores fora de [{limite_inf:.2f}, {limite_sup:.2f}]\n"

    # Teste de distribui√ß√µes
    distribuicoes = {
        "Lognormal": stats.lognorm,
        "Weibull": stats.weibull_min,
        "Exponencial": stats.expon,
        "Gama": stats.gamma
    }

    melhores = []
    for nome, dist in distribuicoes.items():
        try:
            params = dist.fit(dados)
            D, p_valor = kstest(dados, dist.name, args=params)
            melhores.append((nome, p_valor, dist, params))
        except Exception:
            continue

    melhores.sort(key=lambda x: x[1], reverse=True)

    if melhores and melhores[0][1] > 0.05:
        nome, p, dist, params = melhores[0]
        texto += f"\nüìä **Melhor distribui√ß√£o ajustada:** {nome} (p = {p:.4f})\n"

        # C√°lculo baseado na curva ajustada
        p_baixo = dist.cdf(lsl, *params)
        p_cima = 1 - dist.cdf(usl, *params)
        total_defeitos = (p_baixo + p_cima) * 100
        sigma_aprox = stats.norm.ppf(1 - (total_defeitos / 200))

        texto += f"- % fora dos limites: {total_defeitos:.2f}%\n"
        texto += f"- N√≠vel Sigma estimado: {sigma_aprox:.2f} (longo prazo)\n"

        # Gr√°fico com curva ajustada
        aplicar_estilo_minitab()
        x = np.linspace(min(dados), max(dados), 500)
        y = dist.pdf(x, *params)

        fig, ax = plt.subplots(figsize=(8, 4))
        ax.hist(dados, bins=20, color="#A6CEE3", edgecolor='black', density=True, alpha=0.7, label="Histograma")
        ax.plot(x, y, 'darkred', lw=2, label=f'{nome} ajustada')
        ax.axvline(lsl, color='red', linestyle='--', label='LSL')
        ax.axvline(usl, color='red', linestyle='--', label='USL')
        ax.set_title(f'Capabilidade com Distribui√ß√£o {nome}')
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
        plt.close()

        return texto, img_base64

    # Se nenhuma distribui√ß√£o servir, tenta Johnson
    try:
        pt = PowerTransformer(method='yeo-johnson')
        dados_transformados = pt.fit_transform(dados.reshape(-1, 1)).flatten()
        media_t = np.mean(dados_transformados)
        desvio_t = np.std(dados_transformados, ddof=1)

        cp = (usl - lsl) / (6 * desvio_t)
        cpu = (usl - media_t) / (3 * desvio_t)
        cpl = (media_t - lsl) / (3 * desvio_t)
        cpk = min(cpu, cpl)
        sigma = 3 * cpk

        texto += "\nüîÅ **Transforma√ß√£o Johnson aplicada com sucesso (Yeo-Johnson).**\n"
        texto += f"- Cp: {cp:.4f} | Cpk: {cpk:.4f} | N√≠vel Sigma estimado: {sigma:.2f}\n"

        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.hist(dados_transformados, bins=20, color="#A6CEE3", edgecolor='black', density=True)
        ax.axvline(lsl, color='red', linestyle='--', label='LSL')
        ax.axvline(usl, color='red', linestyle='--', label='USL')
        ax.axvline(media_t, color='darkgreen', linestyle='-', label="M√©dia")
        ax.set_title("Capabilidade com Dados Transformados")
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
        plt.close()

        return texto, img_base64

    except Exception:
        pass

    # Se tudo falhar ‚Äì c√°lculo emp√≠rico
    fora = ((dados < lsl) | (dados > usl)).sum()
    percentual = (fora / n) * 100
    sigma_est = stats.norm.ppf(1 - (percentual / 200))

    texto += "\n‚ùå Nenhuma distribui√ß√£o adequada e transforma√ß√£o falhou.\n"
    texto += f"üîö % fora dos limites: {percentual:.2f}%\n"
    texto += f"üîö N√≠vel sigma estimado: {sigma_est:.2f} (emp√≠rico)\n"

    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(8, 4))
    ax.hist(dados, bins=20, color="#FFCC99", edgecolor='black', density=True)
    ax.axvline(lsl, color='red', linestyle='--', label='LSL')
    ax.axvline(usl, color='red', linestyle='--', label='USL')
    ax.axvline(media, color='darkgreen', linestyle='-', label='M√©dia')
    ax.set_title("Capabilidade Emp√≠rica (sem transforma√ß√£o)")
    ax.legend()
    plt.tight_layout()

    buffer = BytesIO()
    plt.savefig(buffer, format='png')
    buffer.seek(0)
    img_base64 = base64.b64encode(buffer.read()).decode('utf-8')
    plt.close()

    return texto, img_base64


def analise_chi_quadrado(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        raise ValueError("O teste qui-quadrado requer pelo menos duas colunas: uma Y e uma X.")

    col_y = colunas_usadas[0]
    col_x = colunas_usadas[1]
    col_freq = colunas_usadas[2] if len(colunas_usadas) >= 3 else None

    # Se o aluno forneceu a coluna de frequ√™ncia explicitamente
    if col_freq and col_freq in df.columns:
        tabela = df.pivot_table(
            index=col_x,
            columns=col_y,
            values=col_freq,
            aggfunc="sum",
            fill_value=0
        )
    else:
        # Dados linha a linha
        tabela = pd.crosstab(df[col_x], df[col_y])

    # Aplica o teste
    chi2, p, dof, expected = chi2_contingency(tabela)

    # Monta a interpreta√ß√£o
    resumo = f"""üîé **Teste do Qui-Quadrado de Independ√™ncia**

Tabela de Conting√™ncia:
{tabela.to_string()}

Estat√≠stica Qui-Quadrado: {chi2:.4f}
Graus de Liberdade: {dof}
Valor-p: {p:.4f}

"""

    if p < 0.05:
        conclusao = "‚ùóExiste associa√ß√£o estat√≠stica significativa entre as vari√°veis (p < 0.05)."
    else:
        conclusao = "‚úÖ N√£o h√° evid√™ncia estat√≠stica de associa√ß√£o entre as vari√°veis (p ‚â• 0.05)."

    # Gr√°fico de barras agrupadas
    aplicar_estilo_minitab()
    tabela.plot(kind='bar')
    plt.title("Distribui√ß√£o das Categorias")
    plt.xlabel(col_x)
    plt.ylabel("Frequ√™ncia")

    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close()
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return resumo + conclusao, imagem_base64

def analise_regressao_linear_simples(df, colunas):
    colunas = [interpretar_coluna(df, c) for c in colunas]
    X = df[colunas[0]].astype(str).str.strip().str.replace(",", ".").str.replace(r"[^\d\.\-]", "", regex=True)
    Y = df[colunas[1]].astype(str).str.strip().str.replace(",", ".").str.replace(r"[^\d\.\-]", "", regex=True)
    X = pd.to_numeric(X, errors="coerce")
    Y = pd.to_numeric(Y, errors="coerce")
    validos = ~(X.isna() | Y.isna())
    X = X[validos]
    Y = Y[validos]

    if len(X) < 2 or len(Y) < 2:
        raise ValueError("N√£o h√° dados num√©ricos suficientes para a regress√£o.")

    X_const = sm.add_constant(X)
    modelo = sm.OLS(Y, X_const).fit()

    a = modelo.params.iloc[0]
    b = modelo.params.iloc[1]
    p_valor = modelo.pvalues.iloc[1]
    r2 = modelo.rsquared
    r2_ajustado = modelo.rsquared_adj
    erro_padrao = np.sqrt(modelo.mse_resid)

    resumo = f"""
**Equa√ß√£o da reta:**  y = {a:.3f} + {b:.3f}¬∑x  
**Valor-p da inclina√ß√£o:**  {p_valor:.4f}  
**Coeficiente de determina√ß√£o (R¬≤):**  {r2:.4f}  
**R¬≤ ajustado:**  {r2_ajustado:.4f}  
**Erro padr√£o da estimativa:**  {erro_padrao:.4f}
""".strip()

    plt.figure(figsize=(8, 6))
    aplicar_estilo_minitab()
    sns.regplot(x=X, y=Y, ci=None, line_kws={"color": "red"})
    plt.xlabel(colunas[0])
    plt.ylabel(colunas[1])
    plt.title("Regress√£o Linear Simples")

    return resumo, salvar_grafico()


def analise_regressao_linear_multipla(df, colunas):
    colunas = [interpretar_coluna(df, c) for c in colunas]
    aplicar_estilo_minitab()

    y_col = colunas[-1]
    x_cols = colunas[:-1]

    X = df[x_cols].apply(pd.to_numeric, errors='coerce')
    Y = pd.to_numeric(df[y_col], errors='coerce')

    # Remover linhas com NaN
    dados = pd.concat([X, Y], axis=1).dropna()
    X = dados[x_cols]
    Y = dados[y_col]

    if len(dados) < 3:
        raise ValueError("N√£o h√° dados suficientes ap√≥s remo√ß√£o de NaNs para an√°lise.")

    X_const = sm.add_constant(X)
    modelo = sm.OLS(Y, X_const).fit()

    # Equa√ß√£o
    eq_terms = [f"{coef:.2f}*{var}" for var, coef in modelo.params.items() if var != 'const']
    equacao = f"{modelo.params['const']:.2f} + " + " + ".join(eq_terms)

    r2 = modelo.rsquared
    r2_adj = modelo.rsquared_adj
    erro_padrao = modelo.mse_resid**0.5
    p_valor_modelo = modelo.f_pvalue

    # VIF
    vif_data = pd.DataFrame()
    vif_data["Vari√°vel"] = X_const.columns
    vif_data["VIF"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]

    # Res√≠duos
    residuos = modelo.resid
    residuos_padronizados = (residuos - residuos.mean()) / residuos.std()
    outliers = sum(abs(residuos_padronizados) > 3)

    # Anderson-Darling
    stat_ad, crit_vals, sig_levels = stats.anderson(residuos, dist='norm')
    limiar_5 = crit_vals[sig_levels.tolist().index(5.0)]
    passou_normalidade = stat_ad < limiar_5

    # Durbin-Watson
    dw = durbin_watson(residuos)

    texto = f"""üìä Regress√£o Linear M√∫ltipla

üîπ Equa√ß√£o:
Y = {equacao}

üîπ Qualidade do modelo:
- R¬≤ = {r2:.3f}
- R¬≤ ajustado = {r2_adj:.3f}
- Erro padr√£o da estimativa = {erro_padrao:.3f}
- Valor-p do modelo = {p_valor_modelo:.4f}

üîπ VIF (fator de infla√ß√£o da vari√¢ncia):\n""" + \
        "\n".join([f"  - {row['Vari√°vel']}: {row['VIF']:.2f}" for _, row in vif_data.iterrows() if row['Vari√°vel'] != 'const']) + f"""

üîπ Res√≠duos:
- Teste de Anderson-Darling (normalidade, 5%): {'‚úÖ' if passou_normalidade else '‚ùå'} (estat√≠stica = {stat_ad:.4f}, limite cr√≠tico = {limiar_5:.4f})
- Estat√≠stica de Durbin-Watson: {dw:.2f}
- Outliers (res√≠duos padronizados > 3): {outliers}
"""

    # Apenas 1 gr√°fico, conforme combinado: Histograma dos Res√≠duos
    plt.figure(figsize=(6, 4))
    aplicar_estilo_minitab()
    sns.histplot(residuos, kde=True, color="steelblue", edgecolor="black")
    plt.title("Histograma dos Res√≠duos")
    imagem = salvar_grafico()

    return texto.strip(), imagem

def analise_descritiva(df, colunas_usadas):
    coluna_y = colunas_usadas[0]  # ‚úÖ pegando diretamente a coluna
    if coluna_y not in df.columns:
        return (
            "‚ùå A coluna selecionada para an√°lise descritiva n√£o foi encontrada.",
            None
        )

    serie = df[coluna_y].dropna()

    if serie.empty:
        return (
            "‚ùå A coluna selecionada n√£o cont√©m dados num√©ricos v√°lidos.",
            None
        )

    media = serie.mean()
    mediana = serie.median()
    desvio = serie.std()
    variancia = serie.var()
    minimo = serie.min()
    maximo = serie.max()
    q1 = serie.quantile(0.25)
    q3 = serie.quantile(0.75)
    assimetria = serie.skew()
    curtose = serie.kurtosis()
    n = serie.count()

    resumo = f"""üìä **An√°lise Descritiva da coluna '{coluna_y}'**  
- M√©dia: {media:.2f}  
- Mediana: {mediana:.2f}  
- Desvio Padr√£o: {desvio:.2f}  
- Vari√¢ncia: {variancia:.2f}  
- M√≠nimo: {minimo:.2f}  
- 1¬∫ Quartil (Q1): {q1:.2f}  
- 3¬∫ Quartil (Q3): {q3:.2f}  
- M√°ximo: {maximo:.2f}  
- Assimetria: {assimetria:.2f}  
- Curtose: {curtose:.2f}  
- N: {n}"""

    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(8, 1.5))
    sns.boxplot(x=serie, orient='h', ax=ax)
    ax.set_title(f"Boxplot - {coluna_y}")
    ax.set_xlabel(coluna_y)

    buffer = BytesIO()
    plt.tight_layout()
    plt.savefig(buffer, format='png')
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode('utf-8')

    return resumo, imagem_base64

def teste_normalidade(df, colunas_usadas):
    if not colunas_usadas:
        return "‚ùå Nenhuma coluna foi selecionada.", None

    coluna = colunas_usadas[0]
    serie = df[coluna].dropna()

    if serie.empty:
        return "‚ùå A coluna selecionada n√£o cont√©m dados v√°lidos.", None

    resultados = []
    dicas = []

    # Shapiro-Wilk
    stat_sw, p_sw = shapiro(serie)
    conclusao_sw = "‚úÖ Dados normais (p > 0.05)" if p_sw > 0.05 else "‚ùå Dados n√£o normais (p ‚â§ 0.05)"
    resultados.append(f"üîπ Shapiro-Wilk: Estat√≠stica = {stat_sw:.4f}, p = {p_sw:.4f} ‚Üí {conclusao_sw}")

    # Anderson-Darling
    ad = anderson(serie)
    lim_ad = ad.critical_values[2]  # n√≠vel de signific√¢ncia de 5%
    conclusao_ad = "‚úÖ Dados normais" if ad.statistic < lim_ad else "‚ùå Dados n√£o normais"
    resultados.append(f"üîπ Anderson-Darling: Estat√≠stica = {ad.statistic:.4f}, Limite Cr√≠tico (5%) = {lim_ad:.4f} ‚Üí {conclusao_ad}")

    # Kolmogorov-Smirnov com compara√ß√£o √† normal padr√£o
    serie_padronizada = (serie - serie.mean()) / serie.std()
    stat_ks, p_ks = kstest(serie_padronizada, 'norm')
    conclusao_ks = "‚úÖ Dados normais (p > 0.05)" if p_ks > 0.05 else "‚ùå Dados n√£o normais (p ‚â§ 0.05)"
    resultados.append(f"üîπ Kolmogorov-Smirnov: Estat√≠stica = {stat_ks:.4f}, p = {p_ks:.4f} ‚Üí {conclusao_ks}")

    # Se os tr√™s testes forem negativos, mostrar recomenda√ß√µes
    if all("‚ùå" in linha for linha in resultados):
        # Outliers
        q1 = serie.quantile(0.25)
        q3 = serie.quantile(0.75)
        iqr = q3 - q1
        limites = (q1 - 1.5 * iqr, q3 + 1.5 * iqr)
        outliers = serie[(serie < limites[0]) | (serie > limites[1])]
        if not outliers.empty:
            dicas.append("üîé Foram identificados poss√≠veis outliers. Recomendamos investig√°-los e, se apropriado, remov√™-los antes de repetir o teste.")

        # Tamanho da amostra
        if len(serie) <= 30:
            dicas.append("üìâ A amostra cont√©m 30 dados ou menos. Sempre que poss√≠vel, colete pelo menos 50 dados para garantir maior confiabilidade.")

        # Estabilidade do processo
        dicas.append("‚öôÔ∏è Verifique se o processo estava est√°vel no momento da coleta. Mudan√ßas no ambiente, operador ou equipamento podem afetar a distribui√ß√£o.")

    texto = f"""üìä **Teste de Normalidade - Coluna '{coluna}'**  
{chr(10).join(resultados)}

{chr(10).join(dicas)}""" if dicas else f"""üìä **Teste de Normalidade - Coluna '{coluna}'**  
{chr(10).join(resultados)}"""

    # üéØ Gr√°fico de probabilidade normal (estilo Minitab)
    aplicar_estilo_minitab()

    fig, ax = plt.subplots(figsize=(6, 4))
    res = stats.probplot(serie, dist="norm", plot=ax)

    ax.get_lines()[1].set_color("red")  # linha de tend√™ncia em vermelho
    ax.set_title(f"Gr√°fico de Probabilidade de {coluna}", fontsize=14)
    ax.set_xlabel(coluna, fontsize=12)
    ax.set_ylabel("Percentual", fontsize=12)

    from matplotlib.ticker import FuncFormatter
    def formatar_percentual(x, _): return f"{100 * x:.0f}%"
    ax.yaxis.set_major_formatter(FuncFormatter(formatar_percentual))
    ax.grid(True, linestyle="--", alpha=0.7)

    plt.tight_layout()
    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return texto, imagem_base64


def analise_regressao_logistica_binaria(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "‚ùå √â necess√°rio selecionar uma coluna Y (resposta bin√°ria) e pelo menos uma coluna X (num√©rica).", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    y_raw = df[nome_coluna_y].dropna()
    X_raw = df[nomes_colunas_x]
    df_modelo = pd.concat([y_raw, X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y]
    X = df_modelo[nomes_colunas_x]

    if y.dtype == object or str(y.dtype).startswith('category'):
        y = pd.factorize(y)[0]

    X = sm.add_constant(X)
    modelo = sm.Logit(y, X)
    resultado = modelo.fit(disp=0)

    pseudo_r2 = resultado.prsquared
    resumo = resultado.summary2().as_text()

    interpretacao = f"""üìä **Regress√£o Log√≠stica Bin√°ria**  
üîπ Vari√°vel de resposta (Y): {nome_coluna_y}  
üîπ Vari√°veis preditoras (X): {", ".join(nomes_colunas_x)}  
üîπ Pseudo R¬≤: {pseudo_r2:.4f}  

üìå Este modelo estima a probabilidade de um resultado bin√°rio com base nas vari√°veis preditoras.  
- Coeficientes positivos indicam aumento na chance de ocorr√™ncia do evento √† medida que a vari√°vel aumenta.  
- P-valores menores que 0.05 indicam signific√¢ncia estat√≠stica.  
- O Pseudo R¬≤ mede o quanto o modelo se ajusta aos dados (quanto mais pr√≥ximo de 1, melhor)."""

    imagem_base64 = None
    if len(nomes_colunas_x) == 1:
        nome_x = nomes_colunas_x[0]
        x_plot = df_modelo[nome_x]
        y_plot = y

        x_ord = np.linspace(x_plot.min(), x_plot.max(), 100)
        X_pred = sm.add_constant(pd.DataFrame({nome_x: x_ord}))
        y_pred = resultado.predict(X_pred)

        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.scatter(x_plot, y_plot, alpha=0.7, color="black", label="Dados")
        ax.plot(x_ord, y_pred, color="red", linewidth=2, label="Curva Ajustada")
        ax.set_xlabel(nome_x)
        ax.set_ylabel(f"Probabilidade de {nome_coluna_y}")
        ax.set_title("Gr√°fico de Linha Ajustada - Regress√£o Log√≠stica")
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

def analise_regressao_logistica_nominal(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "‚ùå √â necess√°rio selecionar uma coluna Y (nominal com mais de duas categorias) e pelo menos uma coluna X (num√©rica).", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    y_raw = df[nome_coluna_y].dropna()
    X_raw = df[nomes_colunas_x]

    df_modelo = pd.concat([y_raw, X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y].squeeze()
    X = df_modelo[nomes_colunas_x]

    # Converte Y para c√≥digos num√©ricos se for categ√≥rica nominal
    if y.dtype == object or str(y.dtype).startswith("category"):
        y, categorias = pd.factorize(y)

    try:
        X = sm.add_constant(X)
        modelo = sm.MNLogit(y, X)
        resultado = modelo.fit(disp=0)

        pseudo_r2 = 1 - resultado.llf / resultado.llnull
        resumo = resultado.summary().as_text()

        interpretacao = f"""üìä **Regress√£o Log√≠stica Nominal**  
üîπ Vari√°vel de resposta (Y): {nome_coluna_y} (com m√∫ltiplas categorias)  
üîπ Vari√°veis preditoras (X): {", ".join(nomes_colunas_x)}  
üîπ Pseudo R¬≤ (McFadden): {pseudo_r2:.4f}  

üìå Este modelo estima a probabilidade de ocorr√™ncia de cada categoria de Y em fun√ß√£o das vari√°veis X.  
- Coeficientes positivos indicam maior chance de uma categoria espec√≠fica ocorrer.  
- P-valores < 0.05 indicam vari√°veis significativas.  
- O Pseudo R¬≤ mede a qualidade do ajuste do modelo."""

        imagem_base64 = None
        try:
            aplicar_estilo_minitab()
            fig, ax = plt.subplots(figsize=(6, 4))
            df_modelo[nome_coluna_y].value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
            ax.set_title("Distribui√ß√£o da vari√°vel resposta")
            ax.set_xlabel(nome_coluna_y)
            ax.set_ylabel("Frequ√™ncia")
            plt.tight_layout()

            buffer = BytesIO()
            plt.savefig(buffer, format="png")
            plt.close(fig)
            buffer.seek(0)
            imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
        except Exception as e:
            print("Erro ao gerar gr√°fico:", str(e))
            imagem_base64 = None

        return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

    except Exception as e:
        return f"Erro ao ajustar modelo: {str(e)}", None

def analise_regressao_logistica_ordinal(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "‚ùå √â necess√°rio selecionar uma coluna Y (ordinal) e pelo menos uma coluna X.", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    # Prepara Y e converte para ordinal, se necess√°rio
    y_raw = df[nome_coluna_y].dropna()
    if not pd.api.types.is_categorical_dtype(y_raw) or not y_raw.cat.ordered:
        categorias_ordenadas = sorted(y_raw.dropna().unique())
        y = pd.Categorical(y_raw, categories=categorias_ordenadas, ordered=True)
    else:
        y = y_raw

    # Converte X para num√©rico
    X_raw = df[nomes_colunas_x].copy()
    for col in nomes_colunas_x:
        X_raw[col] = pd.to_numeric(X_raw[col], errors="coerce")

    # Junta e remove linhas com dados ausentes
    df_modelo = pd.concat([pd.Series(y, name=nome_coluna_y), X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y]
    X = df_modelo[nomes_colunas_x]

    try:
        modelo = OrderedModel(y, X, distr="logit")
        resultado = modelo.fit(method="bfgs", disp=0)

        pseudo_r2 = 1 - resultado.llf / resultado.llnull
        resumo = resultado.summary().as_text()

        interpretacao = f"""üìä **Regress√£o Log√≠stica Ordinal**  
üîπ Vari√°vel de resposta (Y): {nome_coluna_y} (categorias com ordem definida)  
üîπ Vari√°veis preditoras (X): {", ".join(nomes_colunas_x)}  
üîπ Pseudo R¬≤ (McFadden): {pseudo_r2:.4f}  

üìå Este modelo estima a probabilidade acumulada de estar em uma determinada categoria ordinal ou inferior.  
- Coeficientes positivos indicam maior chance de estar em categorias mais altas.  
- P-valores < 0.05 indicam vari√°veis preditoras estatisticamente significativas."""

        imagem_base64 = None
        try:
            aplicar_estilo_minitab()
            fig, ax = plt.subplots(figsize=(6, 4))
            df_modelo[nome_coluna_y].value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
            ax.set_title("Distribui√ß√£o da vari√°vel resposta")
            ax.set_xlabel(nome_coluna_y)
            ax.set_ylabel("Frequ√™ncia")
            plt.tight_layout()

            buffer = BytesIO()
            plt.savefig(buffer, format="png")
            plt.close(fig)
            buffer.seek(0)
            imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
        except Exception as e:
            print("Erro ao gerar gr√°fico:", str(e))
            imagem_base64 = None

        return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

    except Exception as e:
        return f"Erro ao ajustar modelo: {str(e)}", None

def teste_2sample_t(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "‚ùå √â necess√°rio selecionar exatamente duas colunas num√©ricas para o Teste 2 Sample T.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce").dropna()
    serie2 = pd.to_numeric(df[col2], errors="coerce").dropna()

    if len(serie1) < 2 or len(serie2) < 2:
        return "‚ùå As colunas selecionadas n√£o possuem dados suficientes para o teste.", None

    # Teste de normalidade para cada grupo (Anderson-Darling)
    ad1 = anderson(serie1)
    ad2 = anderson(serie2)
    lim1 = ad1.critical_values[2]
    lim2 = ad2.critical_values[2]
    normal1 = ad1.statistic < lim1
    normal2 = ad2.statistic < lim2

    # Teste F para igualdade de vari√¢ncias
    stat_f = np.var(serie1, ddof=1) / np.var(serie2, ddof=1)
    df1, df2 = len(serie1)-1, len(serie2)-1
    p_f = 2 * min(stats.f.cdf(stat_f, df1, df2), 1 - stats.f.cdf(stat_f, df1, df2))
    equal_var = p_f > 0.05

    # Teste t
    t_stat, p_valor = stats.ttest_ind(serie1, serie2, equal_var=equal_var)

    texto = f"""üìä **Teste T para 2 Amostras Independentes**

üîπ Coluna 1: {col1}  
üîπ Coluna 2: {col2}  

üîπ Teste de normalidade (Anderson-Darling, 5%):  
- {col1}: {"‚úÖ Normal" if normal1 else "‚ùå N√£o normal"} (estat√≠stica = {ad1.statistic:.4f}, limite cr√≠tico = {lim1:.4f})  
- {col2}: {"‚úÖ Normal" if normal2 else "‚ùå N√£o normal"} (estat√≠stica = {ad2.statistic:.4f}, limite cr√≠tico = {lim2:.4f})  

üîπ Teste F para igualdade de vari√¢ncias:  
- Estat√≠stica F = {stat_f:.4f}, p = {p_f:.4f} ‚Üí {"‚úÖ Vari√¢ncias iguais" if equal_var else "‚ùå Vari√¢ncias diferentes"}

üîπ Resultado do Teste T:  
- Estat√≠stica t = {t_stat:.4f}, p = {p_valor:.4f}  
- {"‚úÖ N√£o h√° diferen√ßa significativa" if p_valor > 0.05 else "‚ùå Diferen√ßa estatisticamente significativa entre as m√©dias"}"""

    # Gr√°fico estilo Minitab
    try:
        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(6, 4))

        dados_plot = pd.DataFrame({
            'Valor': pd.concat([serie1, serie2]),
            'Grupo': [col1] * len(serie1) + [col2] * len(serie2)
        })

        sns.boxplot(x="Grupo", y="Valor", data=dados_plot, ax=ax, width=0.6, palette="pastel")
        medias = dados_plot.groupby("Grupo")["Valor"].mean()
        ax.plot(range(len(medias)), medias, marker="o", linestyle="-", color="black", linewidth=2, label="M√©dia")
        ax.set_title(f"Boxplot de {col1} e {col2}")
        ax.set_ylabel("Valores")
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
    except:
        imagem_base64 = None

    return texto, imagem_base64

def analise_teste_paired_t(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "‚ùå O teste pareado requer exatamente duas colunas.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce")
    serie2 = pd.to_numeric(df[col2], errors="coerce")

    diferencas = (serie1 - serie2).dropna()
    if len(diferencas) < 2:
        return "‚ùå Dados insuficientes para o teste pareado.", None

    stat, p_valor = stats.ttest_rel(serie1, serie2, nan_policy='omit')
    media = diferencas.mean()
    desvio = diferencas.std(ddof=1)
    n = len(diferencas)

    t_crit = stats.t.ppf(1 - 0.025, df=n - 1)
    erro = desvio / np.sqrt(n)
    ic = (media - t_crit * erro, media + t_crit * erro)

    interpretacao = f"""üìä **Teste T Pareado**  
üîπ Compara√ß√£o entre: {col1} e {col2}  
üîπ N√∫mero de pares: {n}  
üîπ M√©dia das diferen√ßas: {media:.4f}  
üîπ Desvio padr√£o das diferen√ßas: {desvio:.4f}  
üîπ Intervalo de confian√ßa (95%): ({ic[0]:.4f}, {ic[1]:.4f})  
üîπ Valor-p: {p_valor:.4f}  

üìå **Conclus√£o**: {"‚ùå As m√©dias s√£o estatisticamente diferentes." if p_valor < 0.05 else "‚úÖ N√£o h√° diferen√ßa estat√≠stica entre as m√©dias."}"""

    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.boxplot(diferencas, vert=False, patch_artist=True, boxprops=dict(facecolor='skyblue'))
    ax.set_title("Boxplot das Diferen√ßas")
    ax.set_xlabel("Diferen√ßas")
    ax.axvline(0, color='gray', linestyle='--', linewidth=1)
    ax.plot(media, 1, marker="x", color="red", markersize=10, label="M√©dia")
    ax.hlines(1, ic[0], ic[1], color="black", linewidth=2, label="IC 95%")
    ax.legend()
    plt.tight_layout()

    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return interpretacao, imagem_base64

def teste_variancias(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "‚ùå Selecione exatamente duas colunas para comparar as vari√¢ncias.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce").dropna()
    serie2 = pd.to_numeric(df[col2], errors="coerce").dropna()

    if len(serie1) < 3 or len(serie2) < 3:
        return "‚ùå √â necess√°rio pelo menos 3 dados em cada grupo para realizar o teste de vari√¢ncias.", None

    # üß™ Teste de normalidade (Anderson-Darling)
    p_norm1 = anderson(serie1).critical_values[2]
    p_norm2 = anderson(serie2).critical_values[2]
    normal1 = stats.normaltest(serie1).pvalue > 0.05
    normal2 = stats.normaltest(serie2).pvalue > 0.05

    aviso = ""
    if not (normal1 and normal2):
        aviso = "‚ö†Ô∏è A premissa de normalidade foi violada em pelo menos um dos grupos.\n\n"

    # üß™ Teste F
    stat_f = np.var(serie1, ddof=1) / np.var(serie2, ddof=1)
    df1, df2 = len(serie1)-1, len(serie2)-1
    p_f = 2 * min(stats.f.cdf(stat_f, df1, df2), 1 - stats.f.cdf(stat_f, df1, df2))

    interpretacao = f"""üìä **Teste de Igualdade de Vari√¢ncias (F-Teste)**  
üîπ Grupos comparados: {col1} e {col2}  
üîπ Estat√≠stica F: {stat_f:.4f}  
üîπ Valor-p (bilateral): {p_f:.4f}  

{"‚úÖ As vari√¢ncias s√£o significativamente diferentes." if p_f < 0.05 else "‚ûñ N√£o h√° evid√™ncia de diferen√ßa entre as vari√¢ncias."}
"""

    # üé® Gr√°fico de boxplot com estilo Minitab
    try:
        aplicar_estilo_minitab()
        df_plot = pd.DataFrame({
            "Valor": pd.concat([serie1, serie2]),
            "Grupo": [col1] * len(serie1) + [col2] * len(serie2)
        })
        plt.figure(figsize=(8, 5))
        sns.boxplot(x="Valor", y="Grupo", data=df_plot, orient="h", palette="pastel", showmeans=True,
                    meanprops={"marker": "o", "markerfacecolor": "black", "markeredgecolor": "black"})
        plt.title("Compara√ß√£o das Vari√¢ncias (Boxplot)")
        imagem_base64 = salvar_grafico()
    except Exception as e:
        print("Erro ao gerar gr√°fico:", str(e))
        imagem_base64 = None

    return aviso + "```\n" + interpretacao + "\n```", imagem_base64

def teste_anova(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "‚ùå O Teste ANOVA exige no m√≠nimo duas colunas com dados num√©ricos (grupos).", None

    dados_grupos = [df[coluna].dropna() for coluna in colunas_usadas]
    normalidade = []
    for i, grupo in enumerate(dados_grupos):
        stat, critico, _ = stats.anderson(grupo)
        if stat < critico[2]:  # 5%
            normalidade.append(f"‚úÖ Grupo {colunas_usadas[i]}: distribui√ß√£o normal (Anderson-Darling)")
        else:
            normalidade.append(f"‚ö†Ô∏è Grupo {colunas_usadas[i]}: n√£o segue distribui√ß√£o normal")

    # Teste ANOVA
    try:
        f_stat, p_valor = stats.f_oneway(*dados_grupos)
    except Exception as e:
        return f"‚ùå Erro ao executar o teste ANOVA: {str(e)}", None

    # Interpreta√ß√£o
    interpretacao = f"""üìä **Teste ANOVA (An√°lise de Vari√¢ncia)**  
üîπ Grupos comparados: {", ".join(colunas_usadas)}  
üîπ Estat√≠stica F: {f_stat:.4f}  
üîπ Valor-p: {p_valor:.4f}  

üìå Este teste verifica se h√° diferen√ßa significativa entre as m√©dias dos grupos.  
- Se **valor-p < 0.05**, rejeitamos H‚ÇÄ e conclu√≠mos que **pelo menos um grupo tem m√©dia diferente**.
- Se **valor-p ‚â• 0.05**, **n√£o h√° evid√™ncias suficientes** para afirmar que as m√©dias diferem.

üîç **Verifica√ß√£o de normalidade (Anderson-Darling, 5%)**:
""" + "\n".join(normalidade)

    # Gr√°fico
    try:
        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(8, 5))
        ax.boxplot(dados_grupos, vert=False, patch_artist=True,
                   labels=colunas_usadas, boxprops=dict(facecolor="skyblue"))
        medias = [grupo.mean() for grupo in dados_grupos]
        for i, media in enumerate(medias, start=1):
            ax.plot(media, i, marker="o", color="red")
        ax.set_title("Boxplot por Grupo (ANOVA)")
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
    except Exception as e:
        print("Erro ao gerar o gr√°fico:", str(e))
        imagem_base64 = None

    return interpretacao, imagem_base64



# Dicion√°rio de an√°lises estat√≠sticas
ANALISES = {
    "regressao_simples": analise_regressao_linear_simples,
    "regressao_multipla": analise_regressao_linear_multipla,
    "analise_descritiva": analise_descritiva,
    "teste_normalidade": teste_normalidade,
    "regressao_logistica_binaria": analise_regressao_logistica_binaria,
    "regressao_logistica_nominal": analise_regressao_logistica_nominal,
    "regressao_logistica_ordinal": analise_regressao_logistica_ordinal,
    "teste_2sample_t": teste_2sample_t,
    "teste_paired_t": analise_teste_paired_t,
    "teste_variancias": teste_variancias,
    "teste_anova": teste_anova,
    "analise_chi_quadrado": analise_chi_quadrado,
    "capabilidade_normal": analise_capabilidade_normal,
    "capabilidade_nao_normal": analise_capabilidade_nao_normal,

}

