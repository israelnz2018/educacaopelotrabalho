# üî¢ Bibliotecas de an√°lise de dados
import pandas as pd
import numpy as np

# üìä Visualiza√ß√£o de dados 
import matplotlib.pyplot as plt
import seaborn as sns

# üì¶ Modelos estat√≠sticos
import statsmodels.api as sm
from statsmodels.stats.stattools import durbin_watson
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.miscmodels.ordinal_model import OrderedModel
from scipy.stats import chi2_contingency
from scipy.stats import anderson, shapiro, kstest, norm
from sklearn.preprocessing import PowerTransformer
from statsmodels.stats.diagnostic import normal_ad



# üß™ Testes estat√≠sticos
from scipy import stats
from scipy.stats import shapiro, anderson, kstest, norm

# üìà M√©tricas de modelos
from sklearn.metrics import roc_curve, auc

# üíæ Manipula√ß√£o de arquivos/imagens
import base64
from io import BytesIO
import os

# üß† Fun√ß√µes locais do projeto
from suporte import interpretar_coluna
from estilo import aplicar_estilo_minitab

# ‚úÖ Todas as an√°lises come√ßam abaixo, dentro das fun√ß√µes (nunca aqui fora)



def salvar_grafico():
    caminho = "grafico.png"
    plt.tight_layout()
    plt.savefig(caminho)
    plt.close()
    with open(caminho, "rb") as f:
        img_base64 = base64.b64encode(f.read()).decode("utf-8")
    os.remove(caminho)
    return img_base64

def analise_capabilidade_normal(df, colunas_usadas):
    from scipy.stats import norm, shapiro, anderson, kstest
    from io import BytesIO
    import base64

    nome_coluna_y = colunas_usadas[0]
    nome_coluna_x = colunas_usadas[1]

    dados = df[nome_coluna_y].dropna().astype(float)
    limites = df[nome_coluna_x].dropna().astype(float).unique()

    if len(limites) < 1 or len(limites) > 2:
        raise ValueError("A coluna de limites deve conter um ou dois valores num√©ricos.")

    # Detecta LSL e USL
    LSL, USL = None, None
    if len(limites) == 1:
        # Detecta com base na posi√ß√£o na planilha
        if not pd.isna(df[nome_coluna_x].iloc[1]):
            LSL = limites[0]
        else:
            USL = limites[0]
    else:
        LSL, USL = sorted(limites[:2])

    media = np.mean(dados)
    desvio_padrao = np.std(dados, ddof=1)
    desvio_padrao_pop = np.std(dados, ddof=0)

    # üß™ Testes de normalidade
    sw_stat, sw_p = shapiro(dados)
    ad_result = anderson(dados)
    ad_stat = ad_result.statistic
    ad_critico = ad_result.critical_values[2]  # 5%
    ks_stat, ks_p = kstest(dados, 'norm', args=(media, desvio_padrao))

    normal = False
    if sw_p > 0.05 or ad_stat < ad_critico or ks_p > 0.05:
        normal = True

    if not normal:
        return {
            "analise": f"""‚ùå Os dados **n√£o s√£o normais** segundo os testes de normalidade.
- Shapiro-Wilk: p = {sw_p:.4f}
- Anderson-Darling: estat√≠stica = {ad_stat:.4f} | crit√©rio = {ad_critico:.4f}
- Kolmogorov-Smirnov: p = {ks_p:.4f}

Recomenda-se utilizar a **An√°lise de Capabilidade para Dados N√£o Normais**.""",
            "graficos": [],
            "colunas_utilizadas": colunas_usadas
        }

    # Cp e Cpk (quando poss√≠vel)
    cp = ((USL - LSL) / (6 * desvio_padrao)) if (USL and LSL) else None
    cpu = ((USL - media) / (3 * desvio_padrao)) if USL else None
    cpl = ((media - LSL) / (3 * desvio_padrao)) if LSL else None
    cpk = min(cpu or float('inf'), cpl or float('inf'))

    # Pp e Ppk (quando poss√≠vel)
    pp = ((USL - LSL) / (6 * desvio_padrao_pop)) if (USL and LSL) else None
    ppu = ((USL - media) / (3 * desvio_padrao_pop)) if USL else None
    ppl = ((media - LSL) / (3 * desvio_padrao_pop)) if LSL else None
    ppk = min(ppu or float('inf'), ppl or float('inf'))

    # N√≠vel sigma estimado
    sigma_nivel = 3 * cpk

    # üìà Gr√°fico de Capabilidade Estilo Minitab
    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(8, 4))

    counts, bins, patches = ax.hist(dados, bins=15, color="#A6CEE3", edgecolor='black', alpha=0.9, density=True)

    xmin, xmax = ax.get_xlim()
    x = np.linspace(xmin, xmax, 500)
    p = norm.pdf(x, media, desvio_padrao)
    ax.plot(x, p, 'darkred', linewidth=2)

    if LSL: ax.axvline(LSL, color='maroon', linestyle='--', linewidth=1.5, label='LSL')
    if USL: ax.axvline(USL, color='maroon', linestyle='--', linewidth=1.5, label='USL')
    ax.axvline(media, color='darkgreen', linestyle='-', linewidth=2, label='M√©dia')
    ax.text(media, max(p) * 1.05, "Alvo", ha='center', va='bottom', fontsize=10, color='darkgreen')

    ax.set_title('Capabilidade do Processo (Normal)', fontsize=14, weight='bold')
    ax.set_xlabel(nome_coluna_y)
    ax.set_ylabel('Densidade')
    ax.set_xlim(xmin, xmax)
    ax.legend()
    plt.tight_layout()

    buf = BytesIO()
    plt.savefig(buf, format='png')
    buf.seek(0)
    imagem_base64 = base64.b64encode(buf.read()).decode('utf-8')
    plt.close()

    # Texto explicativo
    texto = f"""üìä **An√°lise de Capabilidade (Distribui√ß√£o Normal)**

- M√©dia: {media:.4f}
- Desvio Padr√£o: {desvio_padrao:.4f}
"""

    if LSL: texto += f"- LSL: {LSL:.4f}\n"
    if USL: texto += f"- USL: {USL:.4f}\n"
    if cp: texto += f"- Cp: {cp:.4f}\n"
    if cpk: texto += f"- Cpk: {cpk:.4f}\n"
    if pp: texto += f"- Pp: {pp:.4f}\n"
    if ppk: texto += f"- Ppk: {ppk:.4f}\n"

    texto += f"- N√≠vel Sigma estimado: {sigma_nivel:.4f}"

    return {
        "analise": texto,
        "graficos": [imagem_base64],
        "colunas_utilizadas": colunas_usadas
    }


def analise_capabilidade_nao_normal(df, colunas_usadas):
    
    nome_coluna_y = colunas_usadas[0]
    nome_coluna_x = colunas_usadas[1]

    dados = df[nome_coluna_y].dropna().astype(float)
    limites = df[nome_coluna_x].dropna().unique()

    if len(limites) < 1 or len(limites) > 2:
        raise ValueError("A coluna de limites deve conter um ou dois valores num√©ricos (LSL e/ou USL).")

    lsl = usl = None
    if len(limites) == 2:
        lsl, usl = sorted(limites)
    elif len(limites) == 1:
        if df[nome_coluna_x].iloc[1] != '':
            lsl = limites[0]
        else:
            usl = limites[0]

    # üîç Teste de normalidade (sem mostrar para o aluno)
    media = np.mean(dados)
    desvio = np.std(dados, ddof=1)
    normal1 = shapiro(dados)[1] > 0.05
    normal2 = kstest(dados, 'norm', args=(media, desvio))[1] > 0.05
    normal3 = anderson(dados).statistic < 0.6810

    if normal1 or normal2 or normal3:
        texto = "üìä **An√°lise de Capabilidade**\n\n‚úÖ Os dados parecem seguir uma distribui√ß√£o normal. Recomenda-se utilizar a an√°lise de capabilidade normal."
        return texto, None

    # üß™ Tentar ajuste com distribui√ß√µes alternativas
    distribuicoes = ['lognorm', 'weibull_min', 'gamma', 'expon', 'beta']
    resultados = []

    for dist_name in distribuicoes:
        dist = getattr(stats, dist_name)
        try:
            params = dist.fit(dados)
            stat, p = kstest(dados, dist_name, args=params)
            resultados.append((dist_name, p, params))
        except Exception:
            continue

    resultados.sort(key=lambda x: x[1], reverse=True)

    texto = "üìä **Teste de Ader√™ncia √†s Distribui√ß√µes**\n\n"
    for nome, pval, _ in resultados:
        texto += f"- {nome}: p = {pval:.4f}\n"

    if len(resultados) == 0:
        texto += "\n‚ùå Nenhuma distribui√ß√£o p√¥de ser ajustada."
        texto += "\n\nüîÅ Recomenda-se aplicar transforma√ß√£o matem√°tica (ex: Yeo-Johnson)."
        return texto, None

    melhor_nome, melhor_p, melhor_params = resultados[0]

    if melhor_p > 0.05:
        texto += f"\n‚úÖ **Melhor distribui√ß√£o encontrada: {melhor_nome} (p = {melhor_p:.4f})**"

        # Gera√ß√£o do gr√°fico com curva ajustada
        x = np.linspace(min(dados), max(dados), 500)
        dist = getattr(stats, melhor_nome)

        try:
            y = dist.pdf(x, *melhor_params)
        except Exception:
            return texto + "\n\n‚ùå Erro ao gerar gr√°fico da distribui√ß√£o.", None

        # Gr√°fico com estilo Minitab
        def aplicar_estilo_minitab():
            plt.style.use('default')
            plt.grid(True, linestyle=':', linewidth=0.5)
            plt.rcParams['axes.facecolor'] = 'white'
            plt.rcParams['axes.edgecolor'] = 'black'
            plt.rcParams['axes.grid'] = True
            plt.rcParams['grid.alpha'] = 0.4

        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.hist(dados, bins=15, density=True, alpha=0.7, color="#A6CEE3", edgecolor='black')
        ax.plot(x, y, 'darkred', linewidth=2)

        media = np.mean(dados)
        if lsl is not None:
            ax.axvline(lsl, color='maroon', linestyle='--')
        if usl is not None:
            ax.axvline(usl, color='maroon', linestyle='--')
        ax.axvline(media, color='darkgreen', linestyle='-', linewidth=2)
        ax.text(media, max(y) * 1.05, "M√©dia", ha='center', fontsize=10, color='darkgreen')

        ax.set_title(f'Capabilidade - {melhor_nome}')
        ax.set_xlabel(nome_coluna_y)
        ax.set_ylabel("Densidade")
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode('utf-8')
        plt.close()

        return texto, imagem_base64

    else:
        texto += "\n\n‚ùå Nenhuma distribui√ß√£o apresentou p > 0.05."
        texto += "\n\nüîÅ Recomenda-se aplicar uma transforma√ß√£o matem√°tica (ex: Yeo-Johnson) para tornar os dados aproximadamente normais e ent√£o calcular a capabilidade."
        return texto, None

def aplicar_transformacao_johnson(df, colunas_usadas):
    nome_coluna_y = colunas_usadas[0]
    nome_coluna_x = colunas_usadas[1]

    dados = df[nome_coluna_y].dropna().astype(float)
    limites = df[nome_coluna_x].dropna().unique()

    if len(limites) < 1 or len(limites) > 2:
        raise ValueError("A coluna de limites deve conter um ou dois valores num√©ricos (LSL e/ou USL).")

    # Definir LSL e USL
    lsl = usl = None
    if len(limites) == 2:
        lsl, usl = sorted(limites)
    elif len(limites) == 1:
        if df[nome_coluna_x].iloc[1] != '':
            lsl = limites[0]
        else:
            usl = limites[0]

    # Aplicar transforma√ß√£o Yeo-Johnson
    pt = PowerTransformer(method='yeo-johnson')
    dados_transformados = pt.fit_transform(dados.values.reshape(-1, 1)).flatten()

    # Teste de normalidade
    stat_ad = anderson(dados_transformados).statistic
    normal = stat_ad < 0.6810

    if normal:
        media = np.mean(dados_transformados)
        desvio = np.std(dados_transformados, ddof=1)

        ppl = ppu = pp = ppk = None
        if lsl is not None:
            ppl = (media - lsl) / (3 * desvio)
        if usl is not None:
            ppu = (usl - media) / (3 * desvio)

        if ppl is not None and ppu is not None:
            pp = (usl - lsl) / (6 * desvio)
            ppk = min(ppl, ppu)
        elif ppl is not None:
            ppk = ppl
        elif ppu is not None:
            ppk = ppu

        sigma_nivel = 3 * ppk if ppk is not None else None

        texto = "üîÅ **Transforma√ß√£o Yeo-Johnson aplicada com sucesso**\n\n"
        texto += f"üìå M√©dia transformada: {media:.4f}\n"
        texto += f"üìå Desvio padr√£o: {desvio:.4f}\n"
        if lsl is not None:
            texto += f"- LSL: {lsl:.4f}\n"
        if usl is not None:
            texto += f"- USL: {usl:.4f}\n"
        if pp is not None:
            texto += f"- Pp: {pp:.4f}\n"
        if ppk is not None:
            texto += f"- Ppk: {ppk:.4f}\n"
        if sigma_nivel is not None:
            texto += f"- N√≠vel Sigma estimado: {sigma_nivel:.4f}"

        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.hist(dados_transformados, bins=15, density=True, alpha=0.7, color="#A6CEE3", edgecolor='black')

        x = np.linspace(min(dados_transformados), max(dados_transformados), 500)
        y = norm.pdf(x, media, desvio)
        ax.plot(x, y, 'darkred', linewidth=2)

        if lsl is not None:
            ax.axvline(lsl, color='maroon', linestyle='--')
        if usl is not None:
            ax.axvline(usl, color='maroon', linestyle='--')
        ax.axvline(media, color='darkgreen', linestyle='-', linewidth=2)
        ax.text(media, max(y) * 1.05, "M√©dia", ha='center', fontsize=10, color='darkgreen')

        ax.set_title("Capabilidade (dados transformados)")
        ax.set_xlabel(nome_coluna_y + " (transformado)")
        ax.set_ylabel("Densidade")
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode('utf-8')
        plt.close()

        return texto, imagem_base64, True

    else:
        # Discretiza√ß√£o: % fora dos limites
        total = len(dados)
        abaixo_lsl = len(dados[dados < lsl]) if lsl is not None else 0
        acima_usl = len(dados[dados > usl]) if usl is not None else 0
        fora = abaixo_lsl + acima_usl
        percentual_fora = fora / total

        # Estimativa sigma via tabela Z inversa (1-tailed)
        try:
            sigma_estimado = norm.ppf(1 - percentual_fora / 2)
        except:
            sigma_estimado = None

        texto = "üîÅ **Transforma√ß√£o Yeo-Johnson falhou em normalizar os dados**\n"
        texto += f"\n‚ùå Dados continuam n√£o normais ap√≥s transforma√ß√£o."
        texto += f"\nüìä Estimando capabilidade com base em dados discretos:"
        texto += f"\n- Total de amostras: {total}"
        if lsl is not None:
            texto += f"\n- Abaixo do LSL: {abaixo_lsl}"
        if usl is not None:
            texto += f"\n- Acima do USL: {acima_usl}"
        texto += f"\n- % Fora dos limites: {percentual_fora:.2%}"
        if sigma_estimado:
            texto += f"\n- N√≠vel Sigma estimado (aproximado): {sigma_estimado:.2f}"

        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.hist(dados, bins=15, color="#A6CEE3", edgecolor='black', alpha=0.8)

        if lsl is not None:
            ax.axvline(lsl, color='maroon', linestyle='--', label='LSL')
        if usl is not None:
            ax.axvline(usl, color='maroon', linestyle='--', label='USL')
        ax.axvline(np.mean(dados), color='darkgreen', linestyle='-', linewidth=2, label='M√©dia')
        ax.set_title("Capabilidade (dados discretos)")
        ax.set_xlabel(nome_coluna_y)
        ax.set_ylabel("Frequ√™ncia")
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format='png')
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode('utf-8')
        plt.close()

        return texto, imagem_base64, False


def analise_chi_quadrado(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        raise ValueError("O teste qui-quadrado requer pelo menos duas colunas: uma Y e uma X.")

    col_y = colunas_usadas[0]
    col_x = colunas_usadas[1]
    col_freq = colunas_usadas[2] if len(colunas_usadas) >= 3 else None

    # Se o aluno forneceu a coluna de frequ√™ncia explicitamente
    if col_freq and col_freq in df.columns:
        tabela = df.pivot_table(
            index=col_x,
            columns=col_y,
            values=col_freq,
            aggfunc="sum",
            fill_value=0
        )
    else:
        # Dados linha a linha
        tabela = pd.crosstab(df[col_x], df[col_y])

    # Aplica o teste
    chi2, p, dof, expected = chi2_contingency(tabela)

    # Monta a interpreta√ß√£o
    resumo = f"""üîé **Teste do Qui-Quadrado de Independ√™ncia**

Tabela de Conting√™ncia:
{tabela.to_string()}

Estat√≠stica Qui-Quadrado: {chi2:.4f}
Graus de Liberdade: {dof}
Valor-p: {p:.4f}

"""

    if p < 0.05:
        conclusao = "‚ùóExiste associa√ß√£o estat√≠stica significativa entre as vari√°veis (p < 0.05)."
    else:
        conclusao = "‚úÖ N√£o h√° evid√™ncia estat√≠stica de associa√ß√£o entre as vari√°veis (p ‚â• 0.05)."

    # Gr√°fico de barras agrupadas
    aplicar_estilo_minitab()
    tabela.plot(kind='bar')
    plt.title("Distribui√ß√£o das Categorias")
    plt.xlabel(col_x)
    plt.ylabel("Frequ√™ncia")

    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close()
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return resumo + conclusao, imagem_base64

def analise_regressao_linear_simples(df, colunas):
    colunas = [interpretar_coluna(df, c) for c in colunas]
    X = df[colunas[0]].astype(str).str.strip().str.replace(",", ".").str.replace(r"[^\d\.\-]", "", regex=True)
    Y = df[colunas[1]].astype(str).str.strip().str.replace(",", ".").str.replace(r"[^\d\.\-]", "", regex=True)
    X = pd.to_numeric(X, errors="coerce")
    Y = pd.to_numeric(Y, errors="coerce")
    validos = ~(X.isna() | Y.isna())
    X = X[validos]
    Y = Y[validos]

    if len(X) < 2 or len(Y) < 2:
        raise ValueError("N√£o h√° dados num√©ricos suficientes para a regress√£o.")

    X_const = sm.add_constant(X)
    modelo = sm.OLS(Y, X_const).fit()

    a = modelo.params.iloc[0]
    b = modelo.params.iloc[1]
    p_valor = modelo.pvalues.iloc[1]
    r2 = modelo.rsquared
    r2_ajustado = modelo.rsquared_adj
    erro_padrao = np.sqrt(modelo.mse_resid)

    resumo = f"""
**Equa√ß√£o da reta:**  y = {a:.3f} + {b:.3f}¬∑x  
**Valor-p da inclina√ß√£o:**  {p_valor:.4f}  
**Coeficiente de determina√ß√£o (R¬≤):**  {r2:.4f}  
**R¬≤ ajustado:**  {r2_ajustado:.4f}  
**Erro padr√£o da estimativa:**  {erro_padrao:.4f}
""".strip()

    plt.figure(figsize=(8, 6))
    aplicar_estilo_minitab()
    sns.regplot(x=X, y=Y, ci=None, line_kws={"color": "red"})
    plt.xlabel(colunas[0])
    plt.ylabel(colunas[1])
    plt.title("Regress√£o Linear Simples")

    return resumo, salvar_grafico()


def analise_regressao_linear_multipla(df, colunas):
    colunas = [interpretar_coluna(df, c) for c in colunas]
    aplicar_estilo_minitab()

    y_col = colunas[-1]
    x_cols = colunas[:-1]

    X = df[x_cols].apply(pd.to_numeric, errors='coerce')
    Y = pd.to_numeric(df[y_col], errors='coerce')

    # Remover linhas com NaN
    dados = pd.concat([X, Y], axis=1).dropna()
    X = dados[x_cols]
    Y = dados[y_col]

    if len(dados) < 3:
        raise ValueError("N√£o h√° dados suficientes ap√≥s remo√ß√£o de NaNs para an√°lise.")

    X_const = sm.add_constant(X)
    modelo = sm.OLS(Y, X_const).fit()

    # Equa√ß√£o
    eq_terms = [f"{coef:.2f}*{var}" for var, coef in modelo.params.items() if var != 'const']
    equacao = f"{modelo.params['const']:.2f} + " + " + ".join(eq_terms)

    r2 = modelo.rsquared
    r2_adj = modelo.rsquared_adj
    erro_padrao = modelo.mse_resid**0.5
    p_valor_modelo = modelo.f_pvalue

    # VIF
    vif_data = pd.DataFrame()
    vif_data["Vari√°vel"] = X_const.columns
    vif_data["VIF"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]

    # Res√≠duos
    residuos = modelo.resid
    residuos_padronizados = (residuos - residuos.mean()) / residuos.std()
    outliers = sum(abs(residuos_padronizados) > 3)

    # Anderson-Darling
    stat_ad, crit_vals, sig_levels = stats.anderson(residuos, dist='norm')
    limiar_5 = crit_vals[sig_levels.tolist().index(5.0)]
    passou_normalidade = stat_ad < limiar_5

    # Durbin-Watson
    dw = durbin_watson(residuos)

    texto = f"""üìä Regress√£o Linear M√∫ltipla

üîπ Equa√ß√£o:
Y = {equacao}

üîπ Qualidade do modelo:
- R¬≤ = {r2:.3f}
- R¬≤ ajustado = {r2_adj:.3f}
- Erro padr√£o da estimativa = {erro_padrao:.3f}
- Valor-p do modelo = {p_valor_modelo:.4f}

üîπ VIF (fator de infla√ß√£o da vari√¢ncia):\n""" + \
        "\n".join([f"  - {row['Vari√°vel']}: {row['VIF']:.2f}" for _, row in vif_data.iterrows() if row['Vari√°vel'] != 'const']) + f"""

üîπ Res√≠duos:
- Teste de Anderson-Darling (normalidade, 5%): {'‚úÖ' if passou_normalidade else '‚ùå'} (estat√≠stica = {stat_ad:.4f}, limite cr√≠tico = {limiar_5:.4f})
- Estat√≠stica de Durbin-Watson: {dw:.2f}
- Outliers (res√≠duos padronizados > 3): {outliers}
"""

    # Apenas 1 gr√°fico, conforme combinado: Histograma dos Res√≠duos
    plt.figure(figsize=(6, 4))
    aplicar_estilo_minitab()
    sns.histplot(residuos, kde=True, color="steelblue", edgecolor="black")
    plt.title("Histograma dos Res√≠duos")
    imagem = salvar_grafico()

    return texto.strip(), imagem

def analise_descritiva(df, colunas_usadas):
    coluna_y = colunas_usadas[0]  # ‚úÖ pegando diretamente a coluna
    if coluna_y not in df.columns:
        return (
            "‚ùå A coluna selecionada para an√°lise descritiva n√£o foi encontrada.",
            None
        )

    serie = df[coluna_y].dropna()

    if serie.empty:
        return (
            "‚ùå A coluna selecionada n√£o cont√©m dados num√©ricos v√°lidos.",
            None
        )

    media = serie.mean()
    mediana = serie.median()
    desvio = serie.std()
    variancia = serie.var()
    minimo = serie.min()
    maximo = serie.max()
    q1 = serie.quantile(0.25)
    q3 = serie.quantile(0.75)
    assimetria = serie.skew()
    curtose = serie.kurtosis()
    n = serie.count()

    resumo = f"""üìä **An√°lise Descritiva da coluna '{coluna_y}'**  
- M√©dia: {media:.2f}  
- Mediana: {mediana:.2f}  
- Desvio Padr√£o: {desvio:.2f}  
- Vari√¢ncia: {variancia:.2f}  
- M√≠nimo: {minimo:.2f}  
- 1¬∫ Quartil (Q1): {q1:.2f}  
- 3¬∫ Quartil (Q3): {q3:.2f}  
- M√°ximo: {maximo:.2f}  
- Assimetria: {assimetria:.2f}  
- Curtose: {curtose:.2f}  
- N: {n}"""

    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(8, 1.5))
    sns.boxplot(x=serie, orient='h', ax=ax)
    ax.set_title(f"Boxplot - {coluna_y}")
    ax.set_xlabel(coluna_y)

    buffer = BytesIO()
    plt.tight_layout()
    plt.savefig(buffer, format='png')
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode('utf-8')

    return resumo, imagem_base64

def teste_normalidade(df, colunas_usadas):
    if not colunas_usadas:
        return "‚ùå Nenhuma coluna foi selecionada.", None

    coluna = colunas_usadas[0]
    serie = df[coluna].dropna()

    if serie.empty:
        return "‚ùå A coluna selecionada n√£o cont√©m dados v√°lidos.", None

    resultados = []
    dicas = []

    # Shapiro-Wilk
    stat_sw, p_sw = shapiro(serie)
    conclusao_sw = "‚úÖ Dados normais (p > 0.05)" if p_sw > 0.05 else "‚ùå Dados n√£o normais (p ‚â§ 0.05)"
    resultados.append(f"üîπ Shapiro-Wilk: Estat√≠stica = {stat_sw:.4f}, p = {p_sw:.4f} ‚Üí {conclusao_sw}")

    # Anderson-Darling
    ad = anderson(serie)
    lim_ad = ad.critical_values[2]  # n√≠vel de signific√¢ncia de 5%
    conclusao_ad = "‚úÖ Dados normais" if ad.statistic < lim_ad else "‚ùå Dados n√£o normais"
    resultados.append(f"üîπ Anderson-Darling: Estat√≠stica = {ad.statistic:.4f}, Limite Cr√≠tico (5%) = {lim_ad:.4f} ‚Üí {conclusao_ad}")

    # Kolmogorov-Smirnov com compara√ß√£o √† normal padr√£o
    serie_padronizada = (serie - serie.mean()) / serie.std()
    stat_ks, p_ks = kstest(serie_padronizada, 'norm')
    conclusao_ks = "‚úÖ Dados normais (p > 0.05)" if p_ks > 0.05 else "‚ùå Dados n√£o normais (p ‚â§ 0.05)"
    resultados.append(f"üîπ Kolmogorov-Smirnov: Estat√≠stica = {stat_ks:.4f}, p = {p_ks:.4f} ‚Üí {conclusao_ks}")

    # Se os tr√™s testes forem negativos, mostrar recomenda√ß√µes
    if all("‚ùå" in linha for linha in resultados):
        # Outliers
        q1 = serie.quantile(0.25)
        q3 = serie.quantile(0.75)
        iqr = q3 - q1
        limites = (q1 - 1.5 * iqr, q3 + 1.5 * iqr)
        outliers = serie[(serie < limites[0]) | (serie > limites[1])]
        if not outliers.empty:
            dicas.append("üîé Foram identificados poss√≠veis outliers. Recomendamos investig√°-los e, se apropriado, remov√™-los antes de repetir o teste.")

        # Tamanho da amostra
        if len(serie) <= 30:
            dicas.append("üìâ A amostra cont√©m 30 dados ou menos. Sempre que poss√≠vel, colete pelo menos 50 dados para garantir maior confiabilidade.")

        # Estabilidade do processo
        dicas.append("‚öôÔ∏è Verifique se o processo estava est√°vel no momento da coleta. Mudan√ßas no ambiente, operador ou equipamento podem afetar a distribui√ß√£o.")

    texto = f"""üìä **Teste de Normalidade - Coluna '{coluna}'**  
{chr(10).join(resultados)}

{chr(10).join(dicas)}""" if dicas else f"""üìä **Teste de Normalidade - Coluna '{coluna}'**  
{chr(10).join(resultados)}"""

    # üéØ Gr√°fico de probabilidade normal (estilo Minitab)
    aplicar_estilo_minitab()

    fig, ax = plt.subplots(figsize=(6, 4))
    res = stats.probplot(serie, dist="norm", plot=ax)

    ax.get_lines()[1].set_color("red")  # linha de tend√™ncia em vermelho
    ax.set_title(f"Gr√°fico de Probabilidade de {coluna}", fontsize=14)
    ax.set_xlabel(coluna, fontsize=12)
    ax.set_ylabel("Percentual", fontsize=12)

    from matplotlib.ticker import FuncFormatter
    def formatar_percentual(x, _): return f"{100 * x:.0f}%"
    ax.yaxis.set_major_formatter(FuncFormatter(formatar_percentual))
    ax.grid(True, linestyle="--", alpha=0.7)

    plt.tight_layout()
    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return texto, imagem_base64


def analise_regressao_logistica_binaria(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "‚ùå √â necess√°rio selecionar uma coluna Y (resposta bin√°ria) e pelo menos uma coluna X (num√©rica).", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    y_raw = df[nome_coluna_y].dropna()
    X_raw = df[nomes_colunas_x]
    df_modelo = pd.concat([y_raw, X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y]
    X = df_modelo[nomes_colunas_x]

    if y.dtype == object or str(y.dtype).startswith('category'):
        y = pd.factorize(y)[0]

    X = sm.add_constant(X)
    modelo = sm.Logit(y, X)
    resultado = modelo.fit(disp=0)

    pseudo_r2 = resultado.prsquared
    resumo = resultado.summary2().as_text()

    interpretacao = f"""üìä **Regress√£o Log√≠stica Bin√°ria**  
üîπ Vari√°vel de resposta (Y): {nome_coluna_y}  
üîπ Vari√°veis preditoras (X): {", ".join(nomes_colunas_x)}  
üîπ Pseudo R¬≤: {pseudo_r2:.4f}  

üìå Este modelo estima a probabilidade de um resultado bin√°rio com base nas vari√°veis preditoras.  
- Coeficientes positivos indicam aumento na chance de ocorr√™ncia do evento √† medida que a vari√°vel aumenta.  
- P-valores menores que 0.05 indicam signific√¢ncia estat√≠stica.  
- O Pseudo R¬≤ mede o quanto o modelo se ajusta aos dados (quanto mais pr√≥ximo de 1, melhor)."""

    imagem_base64 = None
    if len(nomes_colunas_x) == 1:
        nome_x = nomes_colunas_x[0]
        x_plot = df_modelo[nome_x]
        y_plot = y

        x_ord = np.linspace(x_plot.min(), x_plot.max(), 100)
        X_pred = sm.add_constant(pd.DataFrame({nome_x: x_ord}))
        y_pred = resultado.predict(X_pred)

        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.scatter(x_plot, y_plot, alpha=0.7, color="black", label="Dados")
        ax.plot(x_ord, y_pred, color="red", linewidth=2, label="Curva Ajustada")
        ax.set_xlabel(nome_x)
        ax.set_ylabel(f"Probabilidade de {nome_coluna_y}")
        ax.set_title("Gr√°fico de Linha Ajustada - Regress√£o Log√≠stica")
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

def analise_regressao_logistica_nominal(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "‚ùå √â necess√°rio selecionar uma coluna Y (nominal com mais de duas categorias) e pelo menos uma coluna X (num√©rica).", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    y_raw = df[nome_coluna_y].dropna()
    X_raw = df[nomes_colunas_x]

    df_modelo = pd.concat([y_raw, X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y].squeeze()
    X = df_modelo[nomes_colunas_x]

    # Converte Y para c√≥digos num√©ricos se for categ√≥rica nominal
    if y.dtype == object or str(y.dtype).startswith("category"):
        y, categorias = pd.factorize(y)

    try:
        X = sm.add_constant(X)
        modelo = sm.MNLogit(y, X)
        resultado = modelo.fit(disp=0)

        pseudo_r2 = 1 - resultado.llf / resultado.llnull
        resumo = resultado.summary().as_text()

        interpretacao = f"""üìä **Regress√£o Log√≠stica Nominal**  
üîπ Vari√°vel de resposta (Y): {nome_coluna_y} (com m√∫ltiplas categorias)  
üîπ Vari√°veis preditoras (X): {", ".join(nomes_colunas_x)}  
üîπ Pseudo R¬≤ (McFadden): {pseudo_r2:.4f}  

üìå Este modelo estima a probabilidade de ocorr√™ncia de cada categoria de Y em fun√ß√£o das vari√°veis X.  
- Coeficientes positivos indicam maior chance de uma categoria espec√≠fica ocorrer.  
- P-valores < 0.05 indicam vari√°veis significativas.  
- O Pseudo R¬≤ mede a qualidade do ajuste do modelo."""

        imagem_base64 = None
        try:
            aplicar_estilo_minitab()
            fig, ax = plt.subplots(figsize=(6, 4))
            df_modelo[nome_coluna_y].value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
            ax.set_title("Distribui√ß√£o da vari√°vel resposta")
            ax.set_xlabel(nome_coluna_y)
            ax.set_ylabel("Frequ√™ncia")
            plt.tight_layout()

            buffer = BytesIO()
            plt.savefig(buffer, format="png")
            plt.close(fig)
            buffer.seek(0)
            imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
        except Exception as e:
            print("Erro ao gerar gr√°fico:", str(e))
            imagem_base64 = None

        return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

    except Exception as e:
        return f"Erro ao ajustar modelo: {str(e)}", None

def analise_regressao_logistica_ordinal(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "‚ùå √â necess√°rio selecionar uma coluna Y (ordinal) e pelo menos uma coluna X.", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    # Prepara Y e converte para ordinal, se necess√°rio
    y_raw = df[nome_coluna_y].dropna()
    if not pd.api.types.is_categorical_dtype(y_raw) or not y_raw.cat.ordered:
        categorias_ordenadas = sorted(y_raw.dropna().unique())
        y = pd.Categorical(y_raw, categories=categorias_ordenadas, ordered=True)
    else:
        y = y_raw

    # Converte X para num√©rico
    X_raw = df[nomes_colunas_x].copy()
    for col in nomes_colunas_x:
        X_raw[col] = pd.to_numeric(X_raw[col], errors="coerce")

    # Junta e remove linhas com dados ausentes
    df_modelo = pd.concat([pd.Series(y, name=nome_coluna_y), X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y]
    X = df_modelo[nomes_colunas_x]

    try:
        modelo = OrderedModel(y, X, distr="logit")
        resultado = modelo.fit(method="bfgs", disp=0)

        pseudo_r2 = 1 - resultado.llf / resultado.llnull
        resumo = resultado.summary().as_text()

        interpretacao = f"""üìä **Regress√£o Log√≠stica Ordinal**  
üîπ Vari√°vel de resposta (Y): {nome_coluna_y} (categorias com ordem definida)  
üîπ Vari√°veis preditoras (X): {", ".join(nomes_colunas_x)}  
üîπ Pseudo R¬≤ (McFadden): {pseudo_r2:.4f}  

üìå Este modelo estima a probabilidade acumulada de estar em uma determinada categoria ordinal ou inferior.  
- Coeficientes positivos indicam maior chance de estar em categorias mais altas.  
- P-valores < 0.05 indicam vari√°veis preditoras estatisticamente significativas."""

        imagem_base64 = None
        try:
            aplicar_estilo_minitab()
            fig, ax = plt.subplots(figsize=(6, 4))
            df_modelo[nome_coluna_y].value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
            ax.set_title("Distribui√ß√£o da vari√°vel resposta")
            ax.set_xlabel(nome_coluna_y)
            ax.set_ylabel("Frequ√™ncia")
            plt.tight_layout()

            buffer = BytesIO()
            plt.savefig(buffer, format="png")
            plt.close(fig)
            buffer.seek(0)
            imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
        except Exception as e:
            print("Erro ao gerar gr√°fico:", str(e))
            imagem_base64 = None

        return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

    except Exception as e:
        return f"Erro ao ajustar modelo: {str(e)}", None

def teste_2sample_t(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "‚ùå √â necess√°rio selecionar exatamente duas colunas num√©ricas para o Teste 2 Sample T.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce").dropna()
    serie2 = pd.to_numeric(df[col2], errors="coerce").dropna()

    if len(serie1) < 2 or len(serie2) < 2:
        return "‚ùå As colunas selecionadas n√£o possuem dados suficientes para o teste.", None

    # Teste de normalidade para cada grupo (Anderson-Darling)
    ad1 = anderson(serie1)
    ad2 = anderson(serie2)
    lim1 = ad1.critical_values[2]
    lim2 = ad2.critical_values[2]
    normal1 = ad1.statistic < lim1
    normal2 = ad2.statistic < lim2

    # Teste F para igualdade de vari√¢ncias
    stat_f = np.var(serie1, ddof=1) / np.var(serie2, ddof=1)
    df1, df2 = len(serie1)-1, len(serie2)-1
    p_f = 2 * min(stats.f.cdf(stat_f, df1, df2), 1 - stats.f.cdf(stat_f, df1, df2))
    equal_var = p_f > 0.05

    # Teste t
    t_stat, p_valor = stats.ttest_ind(serie1, serie2, equal_var=equal_var)

    texto = f"""üìä **Teste T para 2 Amostras Independentes**

üîπ Coluna 1: {col1}  
üîπ Coluna 2: {col2}  

üîπ Teste de normalidade (Anderson-Darling, 5%):  
- {col1}: {"‚úÖ Normal" if normal1 else "‚ùå N√£o normal"} (estat√≠stica = {ad1.statistic:.4f}, limite cr√≠tico = {lim1:.4f})  
- {col2}: {"‚úÖ Normal" if normal2 else "‚ùå N√£o normal"} (estat√≠stica = {ad2.statistic:.4f}, limite cr√≠tico = {lim2:.4f})  

üîπ Teste F para igualdade de vari√¢ncias:  
- Estat√≠stica F = {stat_f:.4f}, p = {p_f:.4f} ‚Üí {"‚úÖ Vari√¢ncias iguais" if equal_var else "‚ùå Vari√¢ncias diferentes"}

üîπ Resultado do Teste T:  
- Estat√≠stica t = {t_stat:.4f}, p = {p_valor:.4f}  
- {"‚úÖ N√£o h√° diferen√ßa significativa" if p_valor > 0.05 else "‚ùå Diferen√ßa estatisticamente significativa entre as m√©dias"}"""

    # Gr√°fico estilo Minitab
    try:
        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(6, 4))

        dados_plot = pd.DataFrame({
            'Valor': pd.concat([serie1, serie2]),
            'Grupo': [col1] * len(serie1) + [col2] * len(serie2)
        })

        sns.boxplot(x="Grupo", y="Valor", data=dados_plot, ax=ax, width=0.6, palette="pastel")
        medias = dados_plot.groupby("Grupo")["Valor"].mean()
        ax.plot(range(len(medias)), medias, marker="o", linestyle="-", color="black", linewidth=2, label="M√©dia")
        ax.set_title(f"Boxplot de {col1} e {col2}")
        ax.set_ylabel("Valores")
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
    except:
        imagem_base64 = None

    return texto, imagem_base64

def analise_teste_paired_t(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "‚ùå O teste pareado requer exatamente duas colunas.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce")
    serie2 = pd.to_numeric(df[col2], errors="coerce")

    diferencas = (serie1 - serie2).dropna()
    if len(diferencas) < 2:
        return "‚ùå Dados insuficientes para o teste pareado.", None

    stat, p_valor = stats.ttest_rel(serie1, serie2, nan_policy='omit')
    media = diferencas.mean()
    desvio = diferencas.std(ddof=1)
    n = len(diferencas)

    t_crit = stats.t.ppf(1 - 0.025, df=n - 1)
    erro = desvio / np.sqrt(n)
    ic = (media - t_crit * erro, media + t_crit * erro)

    interpretacao = f"""üìä **Teste T Pareado**  
üîπ Compara√ß√£o entre: {col1} e {col2}  
üîπ N√∫mero de pares: {n}  
üîπ M√©dia das diferen√ßas: {media:.4f}  
üîπ Desvio padr√£o das diferen√ßas: {desvio:.4f}  
üîπ Intervalo de confian√ßa (95%): ({ic[0]:.4f}, {ic[1]:.4f})  
üîπ Valor-p: {p_valor:.4f}  

üìå **Conclus√£o**: {"‚ùå As m√©dias s√£o estatisticamente diferentes." if p_valor < 0.05 else "‚úÖ N√£o h√° diferen√ßa estat√≠stica entre as m√©dias."}"""

    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.boxplot(diferencas, vert=False, patch_artist=True, boxprops=dict(facecolor='skyblue'))
    ax.set_title("Boxplot das Diferen√ßas")
    ax.set_xlabel("Diferen√ßas")
    ax.axvline(0, color='gray', linestyle='--', linewidth=1)
    ax.plot(media, 1, marker="x", color="red", markersize=10, label="M√©dia")
    ax.hlines(1, ic[0], ic[1], color="black", linewidth=2, label="IC 95%")
    ax.legend()
    plt.tight_layout()

    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return interpretacao, imagem_base64

def teste_variancias(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "‚ùå Selecione exatamente duas colunas para comparar as vari√¢ncias.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce").dropna()
    serie2 = pd.to_numeric(df[col2], errors="coerce").dropna()

    if len(serie1) < 3 or len(serie2) < 3:
        return "‚ùå √â necess√°rio pelo menos 3 dados em cada grupo para realizar o teste de vari√¢ncias.", None

    # üß™ Teste de normalidade (Anderson-Darling)
    p_norm1 = anderson(serie1).critical_values[2]
    p_norm2 = anderson(serie2).critical_values[2]
    normal1 = stats.normaltest(serie1).pvalue > 0.05
    normal2 = stats.normaltest(serie2).pvalue > 0.05

    aviso = ""
    if not (normal1 and normal2):
        aviso = "‚ö†Ô∏è A premissa de normalidade foi violada em pelo menos um dos grupos.\n\n"

    # üß™ Teste F
    stat_f = np.var(serie1, ddof=1) / np.var(serie2, ddof=1)
    df1, df2 = len(serie1)-1, len(serie2)-1
    p_f = 2 * min(stats.f.cdf(stat_f, df1, df2), 1 - stats.f.cdf(stat_f, df1, df2))

    interpretacao = f"""üìä **Teste de Igualdade de Vari√¢ncias (F-Teste)**  
üîπ Grupos comparados: {col1} e {col2}  
üîπ Estat√≠stica F: {stat_f:.4f}  
üîπ Valor-p (bilateral): {p_f:.4f}  

{"‚úÖ As vari√¢ncias s√£o significativamente diferentes." if p_f < 0.05 else "‚ûñ N√£o h√° evid√™ncia de diferen√ßa entre as vari√¢ncias."}
"""

    # üé® Gr√°fico de boxplot com estilo Minitab
    try:
        aplicar_estilo_minitab()
        df_plot = pd.DataFrame({
            "Valor": pd.concat([serie1, serie2]),
            "Grupo": [col1] * len(serie1) + [col2] * len(serie2)
        })
        plt.figure(figsize=(8, 5))
        sns.boxplot(x="Valor", y="Grupo", data=df_plot, orient="h", palette="pastel", showmeans=True,
                    meanprops={"marker": "o", "markerfacecolor": "black", "markeredgecolor": "black"})
        plt.title("Compara√ß√£o das Vari√¢ncias (Boxplot)")
        imagem_base64 = salvar_grafico()
    except Exception as e:
        print("Erro ao gerar gr√°fico:", str(e))
        imagem_base64 = None

    return aviso + "```\n" + interpretacao + "\n```", imagem_base64

def teste_anova(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "‚ùå O Teste ANOVA exige no m√≠nimo duas colunas com dados num√©ricos (grupos).", None

    dados_grupos = [df[coluna].dropna() for coluna in colunas_usadas]
    normalidade = []
    for i, grupo in enumerate(dados_grupos):
        stat, critico, _ = stats.anderson(grupo)
        if stat < critico[2]:  # 5%
            normalidade.append(f"‚úÖ Grupo {colunas_usadas[i]}: distribui√ß√£o normal (Anderson-Darling)")
        else:
            normalidade.append(f"‚ö†Ô∏è Grupo {colunas_usadas[i]}: n√£o segue distribui√ß√£o normal")

    # Teste ANOVA
    try:
        f_stat, p_valor = stats.f_oneway(*dados_grupos)
    except Exception as e:
        return f"‚ùå Erro ao executar o teste ANOVA: {str(e)}", None

    # Interpreta√ß√£o
    interpretacao = f"""üìä **Teste ANOVA (An√°lise de Vari√¢ncia)**  
üîπ Grupos comparados: {", ".join(colunas_usadas)}  
üîπ Estat√≠stica F: {f_stat:.4f}  
üîπ Valor-p: {p_valor:.4f}  

üìå Este teste verifica se h√° diferen√ßa significativa entre as m√©dias dos grupos.  
- Se **valor-p < 0.05**, rejeitamos H‚ÇÄ e conclu√≠mos que **pelo menos um grupo tem m√©dia diferente**.
- Se **valor-p ‚â• 0.05**, **n√£o h√° evid√™ncias suficientes** para afirmar que as m√©dias diferem.

üîç **Verifica√ß√£o de normalidade (Anderson-Darling, 5%)**:
""" + "\n".join(normalidade)

    # Gr√°fico
    try:
        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(8, 5))
        ax.boxplot(dados_grupos, vert=False, patch_artist=True,
                   labels=colunas_usadas, boxprops=dict(facecolor="skyblue"))
        medias = [grupo.mean() for grupo in dados_grupos]
        for i, media in enumerate(medias, start=1):
            ax.plot(media, i, marker="o", color="red")
        ax.set_title("Boxplot por Grupo (ANOVA)")
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
    except Exception as e:
        print("Erro ao gerar o gr√°fico:", str(e))
        imagem_base64 = None

    return interpretacao, imagem_base64



# Dicion√°rio de an√°lises estat√≠sticas
ANALISES = {
    "regressao_simples": analise_regressao_linear_simples,
    "regressao_multipla": analise_regressao_linear_multipla,
    "analise_descritiva": analise_descritiva,
    "teste_normalidade": teste_normalidade,
    "regressao_logistica_binaria": analise_regressao_logistica_binaria,
    "regressao_logistica_nominal": analise_regressao_logistica_nominal,
    "regressao_logistica_ordinal": analise_regressao_logistica_ordinal,
    "teste_2sample_t": teste_2sample_t,
    "teste_paired_t": analise_teste_paired_t,
    "teste_variancias": teste_variancias,
    "teste_anova": teste_anova,
    "analise_chi_quadrado": analise_chi_quadrado,
    "capabilidade_normal": analise_capabilidade_normal,
    "capabilidade_nao_normal": analise_capabilidade_nao_normal,
    "Transforma√ß√£o Johnson": aplicar_transformacao_johnson,


}

