# ğŸ”¢ Bibliotecas de anÃ¡lise de dados
import pandas as pd
import numpy as np

# ğŸ“Š VisualizaÃ§Ã£o de dados
import matplotlib.pyplot as plt
import seaborn as sns

# ğŸ“¦ Modelos estatÃ­sticos
import statsmodels.api as sm
from statsmodels.stats.stattools import durbin_watson
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.miscmodels.ordinal_model import OrderedModel
from scipy.stats import chi2_contingency


# ğŸ§ª Testes estatÃ­sticos
from scipy import stats
from scipy.stats import shapiro, anderson, kstest, norm

# ğŸ“ˆ MÃ©tricas de modelos
from sklearn.metrics import roc_curve, auc

# ğŸ’¾ ManipulaÃ§Ã£o de arquivos/imagens
import base64
from io import BytesIO
import os

# ğŸ§  FunÃ§Ãµes locais do projeto
from suporte import interpretar_coluna
from estilo import aplicar_estilo_minitab

# âœ… Todas as anÃ¡lises comeÃ§am abaixo, dentro das funÃ§Ãµes (nunca aqui fora)



def salvar_grafico():
    caminho = "grafico.png"
    plt.tight_layout()
    plt.savefig(caminho)
    plt.close()
    with open(caminho, "rb") as f:
        img_base64 = base64.b64encode(f.read()).decode("utf-8")
    os.remove(caminho)
    return img_base64

def analise_chi_quadrado(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        raise ValueError("O teste qui-quadrado requer pelo menos duas colunas: uma Y e uma X.")

    col_y = colunas_usadas[0]
    col_x = colunas_usadas[1]
    col_freq = colunas_usadas[2] if len(colunas_usadas) >= 3 else None

    # Se o aluno forneceu a coluna de frequÃªncia explicitamente
    if col_freq and col_freq in df.columns:
        tabela = df.pivot_table(
            index=col_x,
            columns=col_y,
            values=col_freq,
            aggfunc="sum",
            fill_value=0
        )
    else:
        # Dados linha a linha
        tabela = pd.crosstab(df[col_x], df[col_y])

    # Aplica o teste
    chi2, p, dof, expected = chi2_contingency(tabela)

    # Monta a interpretaÃ§Ã£o
    resumo = f"""ğŸ” **Teste do Qui-Quadrado de IndependÃªncia**

Tabela de ContingÃªncia:
{tabela.to_string()}

EstatÃ­stica Qui-Quadrado: {chi2:.4f}
Graus de Liberdade: {dof}
Valor-p: {p:.4f}

"""

    if p < 0.05:
        conclusao = "â—Existe associaÃ§Ã£o estatÃ­stica significativa entre as variÃ¡veis (p < 0.05)."
    else:
        conclusao = "âœ… NÃ£o hÃ¡ evidÃªncia estatÃ­stica de associaÃ§Ã£o entre as variÃ¡veis (p â‰¥ 0.05)."

    # GrÃ¡fico de barras agrupadas
    aplicar_estilo_minitab()
    tabela.plot(kind='bar')
    plt.title("DistribuiÃ§Ã£o das Categorias")
    plt.xlabel(col_x)
    plt.ylabel("FrequÃªncia")

    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close()
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return resumo + conclusao, imagem_base64

def analise_regressao_linear_simples(df, colunas):
    colunas = [interpretar_coluna(df, c) for c in colunas]
    X = df[colunas[0]].astype(str).str.strip().str.replace(",", ".").str.replace(r"[^\d\.\-]", "", regex=True)
    Y = df[colunas[1]].astype(str).str.strip().str.replace(",", ".").str.replace(r"[^\d\.\-]", "", regex=True)
    X = pd.to_numeric(X, errors="coerce")
    Y = pd.to_numeric(Y, errors="coerce")
    validos = ~(X.isna() | Y.isna())
    X = X[validos]
    Y = Y[validos]

    if len(X) < 2 or len(Y) < 2:
        raise ValueError("NÃ£o hÃ¡ dados numÃ©ricos suficientes para a regressÃ£o.")

    X_const = sm.add_constant(X)
    modelo = sm.OLS(Y, X_const).fit()

    a = modelo.params.iloc[0]
    b = modelo.params.iloc[1]
    p_valor = modelo.pvalues.iloc[1]
    r2 = modelo.rsquared
    r2_ajustado = modelo.rsquared_adj
    erro_padrao = np.sqrt(modelo.mse_resid)

    resumo = f"""
**EquaÃ§Ã£o da reta:**  y = {a:.3f} + {b:.3f}Â·x  
**Valor-p da inclinaÃ§Ã£o:**  {p_valor:.4f}  
**Coeficiente de determinaÃ§Ã£o (RÂ²):**  {r2:.4f}  
**RÂ² ajustado:**  {r2_ajustado:.4f}  
**Erro padrÃ£o da estimativa:**  {erro_padrao:.4f}
""".strip()

    plt.figure(figsize=(8, 6))
    aplicar_estilo_minitab()
    sns.regplot(x=X, y=Y, ci=None, line_kws={"color": "red"})
    plt.xlabel(colunas[0])
    plt.ylabel(colunas[1])
    plt.title("RegressÃ£o Linear Simples")

    return resumo, salvar_grafico()


def analise_regressao_linear_multipla(df, colunas):
    colunas = [interpretar_coluna(df, c) for c in colunas]
    aplicar_estilo_minitab()

    y_col = colunas[-1]
    x_cols = colunas[:-1]

    X = df[x_cols].apply(pd.to_numeric, errors='coerce')
    Y = pd.to_numeric(df[y_col], errors='coerce')

    # Remover linhas com NaN
    dados = pd.concat([X, Y], axis=1).dropna()
    X = dados[x_cols]
    Y = dados[y_col]

    if len(dados) < 3:
        raise ValueError("NÃ£o hÃ¡ dados suficientes apÃ³s remoÃ§Ã£o de NaNs para anÃ¡lise.")

    X_const = sm.add_constant(X)
    modelo = sm.OLS(Y, X_const).fit()

    # EquaÃ§Ã£o
    eq_terms = [f"{coef:.2f}*{var}" for var, coef in modelo.params.items() if var != 'const']
    equacao = f"{modelo.params['const']:.2f} + " + " + ".join(eq_terms)

    r2 = modelo.rsquared
    r2_adj = modelo.rsquared_adj
    erro_padrao = modelo.mse_resid**0.5
    p_valor_modelo = modelo.f_pvalue

    # VIF
    vif_data = pd.DataFrame()
    vif_data["VariÃ¡vel"] = X_const.columns
    vif_data["VIF"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]

    # ResÃ­duos
    residuos = modelo.resid
    residuos_padronizados = (residuos - residuos.mean()) / residuos.std()
    outliers = sum(abs(residuos_padronizados) > 3)

    # Anderson-Darling
    stat_ad, crit_vals, sig_levels = stats.anderson(residuos, dist='norm')
    limiar_5 = crit_vals[sig_levels.tolist().index(5.0)]
    passou_normalidade = stat_ad < limiar_5

    # Durbin-Watson
    dw = durbin_watson(residuos)

    texto = f"""ğŸ“Š RegressÃ£o Linear MÃºltipla

ğŸ”¹ EquaÃ§Ã£o:
Y = {equacao}

ğŸ”¹ Qualidade do modelo:
- RÂ² = {r2:.3f}
- RÂ² ajustado = {r2_adj:.3f}
- Erro padrÃ£o da estimativa = {erro_padrao:.3f}
- Valor-p do modelo = {p_valor_modelo:.4f}

ğŸ”¹ VIF (fator de inflaÃ§Ã£o da variÃ¢ncia):\n""" + \
        "\n".join([f"  - {row['VariÃ¡vel']}: {row['VIF']:.2f}" for _, row in vif_data.iterrows() if row['VariÃ¡vel'] != 'const']) + f"""

ğŸ”¹ ResÃ­duos:
- Teste de Anderson-Darling (normalidade, 5%): {'âœ…' if passou_normalidade else 'âŒ'} (estatÃ­stica = {stat_ad:.4f}, limite crÃ­tico = {limiar_5:.4f})
- EstatÃ­stica de Durbin-Watson: {dw:.2f}
- Outliers (resÃ­duos padronizados > 3): {outliers}
"""

    # Apenas 1 grÃ¡fico, conforme combinado: Histograma dos ResÃ­duos
    plt.figure(figsize=(6, 4))
    aplicar_estilo_minitab()
    sns.histplot(residuos, kde=True, color="steelblue", edgecolor="black")
    plt.title("Histograma dos ResÃ­duos")
    imagem = salvar_grafico()

    return texto.strip(), imagem

def analise_descritiva(df, colunas_usadas):
    coluna_y = colunas_usadas[0]  # âœ… pegando diretamente a coluna
    if coluna_y not in df.columns:
        return (
            "âŒ A coluna selecionada para anÃ¡lise descritiva nÃ£o foi encontrada.",
            None
        )

    serie = df[coluna_y].dropna()

    if serie.empty:
        return (
            "âŒ A coluna selecionada nÃ£o contÃ©m dados numÃ©ricos vÃ¡lidos.",
            None
        )

    media = serie.mean()
    mediana = serie.median()
    desvio = serie.std()
    variancia = serie.var()
    minimo = serie.min()
    maximo = serie.max()
    q1 = serie.quantile(0.25)
    q3 = serie.quantile(0.75)
    assimetria = serie.skew()
    curtose = serie.kurtosis()
    n = serie.count()

    resumo = f"""ğŸ“Š **AnÃ¡lise Descritiva da coluna '{coluna_y}'**  
- MÃ©dia: {media:.2f}  
- Mediana: {mediana:.2f}  
- Desvio PadrÃ£o: {desvio:.2f}  
- VariÃ¢ncia: {variancia:.2f}  
- MÃ­nimo: {minimo:.2f}  
- 1Âº Quartil (Q1): {q1:.2f}  
- 3Âº Quartil (Q3): {q3:.2f}  
- MÃ¡ximo: {maximo:.2f}  
- Assimetria: {assimetria:.2f}  
- Curtose: {curtose:.2f}  
- N: {n}"""

    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(8, 1.5))
    sns.boxplot(x=serie, orient='h', ax=ax)
    ax.set_title(f"Boxplot - {coluna_y}")
    ax.set_xlabel(coluna_y)

    buffer = BytesIO()
    plt.tight_layout()
    plt.savefig(buffer, format='png')
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode('utf-8')

    return resumo, imagem_base64

def teste_normalidade(df, colunas_usadas):
    if not colunas_usadas:
        return "âŒ Nenhuma coluna foi selecionada.", None

    coluna = colunas_usadas[0]
    serie = df[coluna].dropna()

    if serie.empty:
        return "âŒ A coluna selecionada nÃ£o contÃ©m dados vÃ¡lidos.", None

    resultados = []
    dicas = []

    # Shapiro-Wilk
    stat_sw, p_sw = shapiro(serie)
    conclusao_sw = "âœ… Dados normais (p > 0.05)" if p_sw > 0.05 else "âŒ Dados nÃ£o normais (p â‰¤ 0.05)"
    resultados.append(f"ğŸ”¹ Shapiro-Wilk: EstatÃ­stica = {stat_sw:.4f}, p = {p_sw:.4f} â†’ {conclusao_sw}")

    # Anderson-Darling
    ad = anderson(serie)
    lim_ad = ad.critical_values[2]  # nÃ­vel de significÃ¢ncia de 5%
    conclusao_ad = "âœ… Dados normais" if ad.statistic < lim_ad else "âŒ Dados nÃ£o normais"
    resultados.append(f"ğŸ”¹ Anderson-Darling: EstatÃ­stica = {ad.statistic:.4f}, Limite CrÃ­tico (5%) = {lim_ad:.4f} â†’ {conclusao_ad}")

    # Kolmogorov-Smirnov com comparaÃ§Ã£o Ã  normal padrÃ£o
    serie_padronizada = (serie - serie.mean()) / serie.std()
    stat_ks, p_ks = kstest(serie_padronizada, 'norm')
    conclusao_ks = "âœ… Dados normais (p > 0.05)" if p_ks > 0.05 else "âŒ Dados nÃ£o normais (p â‰¤ 0.05)"
    resultados.append(f"ğŸ”¹ Kolmogorov-Smirnov: EstatÃ­stica = {stat_ks:.4f}, p = {p_ks:.4f} â†’ {conclusao_ks}")

    # Se os trÃªs testes forem negativos, mostrar recomendaÃ§Ãµes
    if all("âŒ" in linha for linha in resultados):
        # Outliers
        q1 = serie.quantile(0.25)
        q3 = serie.quantile(0.75)
        iqr = q3 - q1
        limites = (q1 - 1.5 * iqr, q3 + 1.5 * iqr)
        outliers = serie[(serie < limites[0]) | (serie > limites[1])]
        if not outliers.empty:
            dicas.append("ğŸ” Foram identificados possÃ­veis outliers. Recomendamos investigÃ¡-los e, se apropriado, removÃª-los antes de repetir o teste.")

        # Tamanho da amostra
        if len(serie) <= 30:
            dicas.append("ğŸ“‰ A amostra contÃ©m 30 dados ou menos. Sempre que possÃ­vel, colete pelo menos 50 dados para garantir maior confiabilidade.")

        # Estabilidade do processo
        dicas.append("âš™ï¸ Verifique se o processo estava estÃ¡vel no momento da coleta. MudanÃ§as no ambiente, operador ou equipamento podem afetar a distribuiÃ§Ã£o.")

    texto = f"""ğŸ“Š **Teste de Normalidade - Coluna '{coluna}'**  
{chr(10).join(resultados)}

{chr(10).join(dicas)}""" if dicas else f"""ğŸ“Š **Teste de Normalidade - Coluna '{coluna}'**  
{chr(10).join(resultados)}"""

    # ğŸ¯ GrÃ¡fico de probabilidade normal (estilo Minitab)
    aplicar_estilo_minitab()

    fig, ax = plt.subplots(figsize=(6, 4))
    res = stats.probplot(serie, dist="norm", plot=ax)

    ax.get_lines()[1].set_color("red")  # linha de tendÃªncia em vermelho
    ax.set_title(f"GrÃ¡fico de Probabilidade de {coluna}", fontsize=14)
    ax.set_xlabel(coluna, fontsize=12)
    ax.set_ylabel("Percentual", fontsize=12)

    from matplotlib.ticker import FuncFormatter
    def formatar_percentual(x, _): return f"{100 * x:.0f}%"
    ax.yaxis.set_major_formatter(FuncFormatter(formatar_percentual))
    ax.grid(True, linestyle="--", alpha=0.7)

    plt.tight_layout()
    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return texto, imagem_base64


def analise_regressao_logistica_binaria(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "âŒ Ã‰ necessÃ¡rio selecionar uma coluna Y (resposta binÃ¡ria) e pelo menos uma coluna X (numÃ©rica).", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    y_raw = df[nome_coluna_y].dropna()
    X_raw = df[nomes_colunas_x]
    df_modelo = pd.concat([y_raw, X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y]
    X = df_modelo[nomes_colunas_x]

    if y.dtype == object or str(y.dtype).startswith('category'):
        y = pd.factorize(y)[0]

    X = sm.add_constant(X)
    modelo = sm.Logit(y, X)
    resultado = modelo.fit(disp=0)

    pseudo_r2 = resultado.prsquared
    resumo = resultado.summary2().as_text()

    interpretacao = f"""ğŸ“Š **RegressÃ£o LogÃ­stica BinÃ¡ria**  
ğŸ”¹ VariÃ¡vel de resposta (Y): {nome_coluna_y}  
ğŸ”¹ VariÃ¡veis preditoras (X): {", ".join(nomes_colunas_x)}  
ğŸ”¹ Pseudo RÂ²: {pseudo_r2:.4f}  

ğŸ“Œ Este modelo estima a probabilidade de um resultado binÃ¡rio com base nas variÃ¡veis preditoras.  
- Coeficientes positivos indicam aumento na chance de ocorrÃªncia do evento Ã  medida que a variÃ¡vel aumenta.  
- P-valores menores que 0.05 indicam significÃ¢ncia estatÃ­stica.  
- O Pseudo RÂ² mede o quanto o modelo se ajusta aos dados (quanto mais prÃ³ximo de 1, melhor)."""

    imagem_base64 = None
    if len(nomes_colunas_x) == 1:
        nome_x = nomes_colunas_x[0]
        x_plot = df_modelo[nome_x]
        y_plot = y

        x_ord = np.linspace(x_plot.min(), x_plot.max(), 100)
        X_pred = sm.add_constant(pd.DataFrame({nome_x: x_ord}))
        y_pred = resultado.predict(X_pred)

        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.scatter(x_plot, y_plot, alpha=0.7, color="black", label="Dados")
        ax.plot(x_ord, y_pred, color="red", linewidth=2, label="Curva Ajustada")
        ax.set_xlabel(nome_x)
        ax.set_ylabel(f"Probabilidade de {nome_coluna_y}")
        ax.set_title("GrÃ¡fico de Linha Ajustada - RegressÃ£o LogÃ­stica")
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

def analise_regressao_logistica_nominal(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "âŒ Ã‰ necessÃ¡rio selecionar uma coluna Y (nominal com mais de duas categorias) e pelo menos uma coluna X (numÃ©rica).", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    y_raw = df[nome_coluna_y].dropna()
    X_raw = df[nomes_colunas_x]

    df_modelo = pd.concat([y_raw, X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y].squeeze()
    X = df_modelo[nomes_colunas_x]

    # Converte Y para cÃ³digos numÃ©ricos se for categÃ³rica nominal
    if y.dtype == object or str(y.dtype).startswith("category"):
        y, categorias = pd.factorize(y)

    try:
        X = sm.add_constant(X)
        modelo = sm.MNLogit(y, X)
        resultado = modelo.fit(disp=0)

        pseudo_r2 = 1 - resultado.llf / resultado.llnull
        resumo = resultado.summary().as_text()

        interpretacao = f"""ğŸ“Š **RegressÃ£o LogÃ­stica Nominal**  
ğŸ”¹ VariÃ¡vel de resposta (Y): {nome_coluna_y} (com mÃºltiplas categorias)  
ğŸ”¹ VariÃ¡veis preditoras (X): {", ".join(nomes_colunas_x)}  
ğŸ”¹ Pseudo RÂ² (McFadden): {pseudo_r2:.4f}  

ğŸ“Œ Este modelo estima a probabilidade de ocorrÃªncia de cada categoria de Y em funÃ§Ã£o das variÃ¡veis X.  
- Coeficientes positivos indicam maior chance de uma categoria especÃ­fica ocorrer.  
- P-valores < 0.05 indicam variÃ¡veis significativas.  
- O Pseudo RÂ² mede a qualidade do ajuste do modelo."""

        imagem_base64 = None
        try:
            aplicar_estilo_minitab()
            fig, ax = plt.subplots(figsize=(6, 4))
            df_modelo[nome_coluna_y].value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
            ax.set_title("DistribuiÃ§Ã£o da variÃ¡vel resposta")
            ax.set_xlabel(nome_coluna_y)
            ax.set_ylabel("FrequÃªncia")
            plt.tight_layout()

            buffer = BytesIO()
            plt.savefig(buffer, format="png")
            plt.close(fig)
            buffer.seek(0)
            imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
        except Exception as e:
            print("Erro ao gerar grÃ¡fico:", str(e))
            imagem_base64 = None

        return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

    except Exception as e:
        return f"Erro ao ajustar modelo: {str(e)}", None

def analise_regressao_logistica_ordinal(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "âŒ Ã‰ necessÃ¡rio selecionar uma coluna Y (ordinal) e pelo menos uma coluna X.", None

    nome_coluna_y = colunas_usadas[0]
    nomes_colunas_x = colunas_usadas[1:]

    # Prepara Y e converte para ordinal, se necessÃ¡rio
    y_raw = df[nome_coluna_y].dropna()
    if not pd.api.types.is_categorical_dtype(y_raw) or not y_raw.cat.ordered:
        categorias_ordenadas = sorted(y_raw.dropna().unique())
        y = pd.Categorical(y_raw, categories=categorias_ordenadas, ordered=True)
    else:
        y = y_raw

    # Converte X para numÃ©rico
    X_raw = df[nomes_colunas_x].copy()
    for col in nomes_colunas_x:
        X_raw[col] = pd.to_numeric(X_raw[col], errors="coerce")

    # Junta e remove linhas com dados ausentes
    df_modelo = pd.concat([pd.Series(y, name=nome_coluna_y), X_raw], axis=1).dropna()
    y = df_modelo[nome_coluna_y]
    X = df_modelo[nomes_colunas_x]

    try:
        modelo = OrderedModel(y, X, distr="logit")
        resultado = modelo.fit(method="bfgs", disp=0)

        pseudo_r2 = 1 - resultado.llf / resultado.llnull
        resumo = resultado.summary().as_text()

        interpretacao = f"""ğŸ“Š **RegressÃ£o LogÃ­stica Ordinal**  
ğŸ”¹ VariÃ¡vel de resposta (Y): {nome_coluna_y} (categorias com ordem definida)  
ğŸ”¹ VariÃ¡veis preditoras (X): {", ".join(nomes_colunas_x)}  
ğŸ”¹ Pseudo RÂ² (McFadden): {pseudo_r2:.4f}  

ğŸ“Œ Este modelo estima a probabilidade acumulada de estar em uma determinada categoria ordinal ou inferior.  
- Coeficientes positivos indicam maior chance de estar em categorias mais altas.  
- P-valores < 0.05 indicam variÃ¡veis preditoras estatisticamente significativas."""

        imagem_base64 = None
        try:
            aplicar_estilo_minitab()
            fig, ax = plt.subplots(figsize=(6, 4))
            df_modelo[nome_coluna_y].value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
            ax.set_title("DistribuiÃ§Ã£o da variÃ¡vel resposta")
            ax.set_xlabel(nome_coluna_y)
            ax.set_ylabel("FrequÃªncia")
            plt.tight_layout()

            buffer = BytesIO()
            plt.savefig(buffer, format="png")
            plt.close(fig)
            buffer.seek(0)
            imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
        except Exception as e:
            print("Erro ao gerar grÃ¡fico:", str(e))
            imagem_base64 = None

        return interpretacao + "\n\n```\n" + resumo + "\n```", imagem_base64

    except Exception as e:
        return f"Erro ao ajustar modelo: {str(e)}", None

def teste_2sample_t(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "âŒ Ã‰ necessÃ¡rio selecionar exatamente duas colunas numÃ©ricas para o Teste 2 Sample T.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce").dropna()
    serie2 = pd.to_numeric(df[col2], errors="coerce").dropna()

    if len(serie1) < 2 or len(serie2) < 2:
        return "âŒ As colunas selecionadas nÃ£o possuem dados suficientes para o teste.", None

    # Teste de normalidade para cada grupo (Anderson-Darling)
    ad1 = anderson(serie1)
    ad2 = anderson(serie2)
    lim1 = ad1.critical_values[2]
    lim2 = ad2.critical_values[2]
    normal1 = ad1.statistic < lim1
    normal2 = ad2.statistic < lim2

    # Teste F para igualdade de variÃ¢ncias
    stat_f = np.var(serie1, ddof=1) / np.var(serie2, ddof=1)
    df1, df2 = len(serie1)-1, len(serie2)-1
    p_f = 2 * min(stats.f.cdf(stat_f, df1, df2), 1 - stats.f.cdf(stat_f, df1, df2))
    equal_var = p_f > 0.05

    # Teste t
    t_stat, p_valor = stats.ttest_ind(serie1, serie2, equal_var=equal_var)

    texto = f"""ğŸ“Š **Teste T para 2 Amostras Independentes**

ğŸ”¹ Coluna 1: {col1}  
ğŸ”¹ Coluna 2: {col2}  

ğŸ”¹ Teste de normalidade (Anderson-Darling, 5%):  
- {col1}: {"âœ… Normal" if normal1 else "âŒ NÃ£o normal"} (estatÃ­stica = {ad1.statistic:.4f}, limite crÃ­tico = {lim1:.4f})  
- {col2}: {"âœ… Normal" if normal2 else "âŒ NÃ£o normal"} (estatÃ­stica = {ad2.statistic:.4f}, limite crÃ­tico = {lim2:.4f})  

ğŸ”¹ Teste F para igualdade de variÃ¢ncias:  
- EstatÃ­stica F = {stat_f:.4f}, p = {p_f:.4f} â†’ {"âœ… VariÃ¢ncias iguais" if equal_var else "âŒ VariÃ¢ncias diferentes"}

ğŸ”¹ Resultado do Teste T:  
- EstatÃ­stica t = {t_stat:.4f}, p = {p_valor:.4f}  
- {"âœ… NÃ£o hÃ¡ diferenÃ§a significativa" if p_valor > 0.05 else "âŒ DiferenÃ§a estatisticamente significativa entre as mÃ©dias"}"""

    # GrÃ¡fico estilo Minitab
    try:
        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(6, 4))

        dados_plot = pd.DataFrame({
            'Valor': pd.concat([serie1, serie2]),
            'Grupo': [col1] * len(serie1) + [col2] * len(serie2)
        })

        sns.boxplot(x="Grupo", y="Valor", data=dados_plot, ax=ax, width=0.6, palette="pastel")
        medias = dados_plot.groupby("Grupo")["Valor"].mean()
        ax.plot(range(len(medias)), medias, marker="o", linestyle="-", color="black", linewidth=2, label="MÃ©dia")
        ax.set_title(f"Boxplot de {col1} e {col2}")
        ax.set_ylabel("Valores")
        ax.legend()
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
    except:
        imagem_base64 = None

    return texto, imagem_base64

def analise_teste_paired_t(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "âŒ O teste pareado requer exatamente duas colunas.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce")
    serie2 = pd.to_numeric(df[col2], errors="coerce")

    diferencas = (serie1 - serie2).dropna()
    if len(diferencas) < 2:
        return "âŒ Dados insuficientes para o teste pareado.", None

    stat, p_valor = stats.ttest_rel(serie1, serie2, nan_policy='omit')
    media = diferencas.mean()
    desvio = diferencas.std(ddof=1)
    n = len(diferencas)

    t_crit = stats.t.ppf(1 - 0.025, df=n - 1)
    erro = desvio / np.sqrt(n)
    ic = (media - t_crit * erro, media + t_crit * erro)

    interpretacao = f"""ğŸ“Š **Teste T Pareado**  
ğŸ”¹ ComparaÃ§Ã£o entre: {col1} e {col2}  
ğŸ”¹ NÃºmero de pares: {n}  
ğŸ”¹ MÃ©dia das diferenÃ§as: {media:.4f}  
ğŸ”¹ Desvio padrÃ£o das diferenÃ§as: {desvio:.4f}  
ğŸ”¹ Intervalo de confianÃ§a (95%): ({ic[0]:.4f}, {ic[1]:.4f})  
ğŸ”¹ Valor-p: {p_valor:.4f}  

ğŸ“Œ **ConclusÃ£o**: {"âŒ As mÃ©dias sÃ£o estatisticamente diferentes." if p_valor < 0.05 else "âœ… NÃ£o hÃ¡ diferenÃ§a estatÃ­stica entre as mÃ©dias."}"""

    aplicar_estilo_minitab()
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.boxplot(diferencas, vert=False, patch_artist=True, boxprops=dict(facecolor='skyblue'))
    ax.set_title("Boxplot das DiferenÃ§as")
    ax.set_xlabel("DiferenÃ§as")
    ax.axvline(0, color='gray', linestyle='--', linewidth=1)
    ax.plot(media, 1, marker="x", color="red", markersize=10, label="MÃ©dia")
    ax.hlines(1, ic[0], ic[1], color="black", linewidth=2, label="IC 95%")
    ax.legend()
    plt.tight_layout()

    buffer = BytesIO()
    plt.savefig(buffer, format="png")
    plt.close(fig)
    buffer.seek(0)
    imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")

    return interpretacao, imagem_base64

def teste_variancias(df, colunas_usadas):
    if len(colunas_usadas) != 2:
        return "âŒ Selecione exatamente duas colunas para comparar as variÃ¢ncias.", None

    col1, col2 = colunas_usadas
    serie1 = pd.to_numeric(df[col1], errors="coerce").dropna()
    serie2 = pd.to_numeric(df[col2], errors="coerce").dropna()

    if len(serie1) < 3 or len(serie2) < 3:
        return "âŒ Ã‰ necessÃ¡rio pelo menos 3 dados em cada grupo para realizar o teste de variÃ¢ncias.", None

    # ğŸ§ª Teste de normalidade (Anderson-Darling)
    p_norm1 = anderson(serie1).critical_values[2]
    p_norm2 = anderson(serie2).critical_values[2]
    normal1 = stats.normaltest(serie1).pvalue > 0.05
    normal2 = stats.normaltest(serie2).pvalue > 0.05

    aviso = ""
    if not (normal1 and normal2):
        aviso = "âš ï¸ A premissa de normalidade foi violada em pelo menos um dos grupos.\n\n"

    # ğŸ§ª Teste F
    stat_f = np.var(serie1, ddof=1) / np.var(serie2, ddof=1)
    df1, df2 = len(serie1)-1, len(serie2)-1
    p_f = 2 * min(stats.f.cdf(stat_f, df1, df2), 1 - stats.f.cdf(stat_f, df1, df2))

    interpretacao = f"""ğŸ“Š **Teste de Igualdade de VariÃ¢ncias (F-Teste)**  
ğŸ”¹ Grupos comparados: {col1} e {col2}  
ğŸ”¹ EstatÃ­stica F: {stat_f:.4f}  
ğŸ”¹ Valor-p (bilateral): {p_f:.4f}  

{"âœ… As variÃ¢ncias sÃ£o significativamente diferentes." if p_f < 0.05 else "â– NÃ£o hÃ¡ evidÃªncia de diferenÃ§a entre as variÃ¢ncias."}
"""

    # ğŸ¨ GrÃ¡fico de boxplot com estilo Minitab
    try:
        aplicar_estilo_minitab()
        df_plot = pd.DataFrame({
            "Valor": pd.concat([serie1, serie2]),
            "Grupo": [col1] * len(serie1) + [col2] * len(serie2)
        })
        plt.figure(figsize=(8, 5))
        sns.boxplot(x="Valor", y="Grupo", data=df_plot, orient="h", palette="pastel", showmeans=True,
                    meanprops={"marker": "o", "markerfacecolor": "black", "markeredgecolor": "black"})
        plt.title("ComparaÃ§Ã£o das VariÃ¢ncias (Boxplot)")
        imagem_base64 = salvar_grafico()
    except Exception as e:
        print("Erro ao gerar grÃ¡fico:", str(e))
        imagem_base64 = None

    return aviso + "```\n" + interpretacao + "\n```", imagem_base64

def teste_anova(df, colunas_usadas):
    if len(colunas_usadas) < 2:
        return "âŒ O Teste ANOVA exige no mÃ­nimo duas colunas com dados numÃ©ricos (grupos).", None

    dados_grupos = [df[coluna].dropna() for coluna in colunas_usadas]
    normalidade = []
    for i, grupo in enumerate(dados_grupos):
        stat, critico, _ = stats.anderson(grupo)
        if stat < critico[2]:  # 5%
            normalidade.append(f"âœ… Grupo {colunas_usadas[i]}: distribuiÃ§Ã£o normal (Anderson-Darling)")
        else:
            normalidade.append(f"âš ï¸ Grupo {colunas_usadas[i]}: nÃ£o segue distribuiÃ§Ã£o normal")

    # Teste ANOVA
    try:
        f_stat, p_valor = stats.f_oneway(*dados_grupos)
    except Exception as e:
        return f"âŒ Erro ao executar o teste ANOVA: {str(e)}", None

    # InterpretaÃ§Ã£o
    interpretacao = f"""ğŸ“Š **Teste ANOVA (AnÃ¡lise de VariÃ¢ncia)**  
ğŸ”¹ Grupos comparados: {", ".join(colunas_usadas)}  
ğŸ”¹ EstatÃ­stica F: {f_stat:.4f}  
ğŸ”¹ Valor-p: {p_valor:.4f}  

ğŸ“Œ Este teste verifica se hÃ¡ diferenÃ§a significativa entre as mÃ©dias dos grupos.  
- Se **valor-p < 0.05**, rejeitamos Hâ‚€ e concluÃ­mos que **pelo menos um grupo tem mÃ©dia diferente**.
- Se **valor-p â‰¥ 0.05**, **nÃ£o hÃ¡ evidÃªncias suficientes** para afirmar que as mÃ©dias diferem.

ğŸ” **VerificaÃ§Ã£o de normalidade (Anderson-Darling, 5%)**:
""" + "\n".join(normalidade)

    # GrÃ¡fico
    try:
        aplicar_estilo_minitab()
        fig, ax = plt.subplots(figsize=(8, 5))
        ax.boxplot(dados_grupos, vert=False, patch_artist=True,
                   labels=colunas_usadas, boxprops=dict(facecolor="skyblue"))
        medias = [grupo.mean() for grupo in dados_grupos]
        for i, media in enumerate(medias, start=1):
            ax.plot(media, i, marker="o", color="red")
        ax.set_title("Boxplot por Grupo (ANOVA)")
        plt.tight_layout()

        buffer = BytesIO()
        plt.savefig(buffer, format="png")
        plt.close(fig)
        buffer.seek(0)
        imagem_base64 = base64.b64encode(buffer.read()).decode("utf-8")
    except Exception as e:
        print("Erro ao gerar o grÃ¡fico:", str(e))
        imagem_base64 = None

    return interpretacao, imagem_base64



# DicionÃ¡rio de anÃ¡lises estatÃ­sticas
ANALISES = {
    "regressao_simples": analise_regressao_linear_simples,
    "regressao_multipla": analise_regressao_linear_multipla,
    "analise_descritiva": analise_descritiva,
    "teste_normalidade": teste_normalidade,
    "regressao_logistica_binaria": analise_regressao_logistica_binaria,
    "regressao_logistica_nominal": analise_regressao_logistica_nominal,
    "regressao_logistica_ordinal": analise_regressao_logistica_ordinal,
    "teste_2sample_t": teste_2sample_t,
    "teste_paired_t": analise_teste_paired_t,
    "teste_variancias": teste_variancias,
    "teste_anova": teste_anova,
    "analise_chi_quadrado": analise_chi_quadrado

}

